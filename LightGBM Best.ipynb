{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devthebear_gmail_com/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "predictors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Helper function ###########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(df, column_name):\n",
    "    df_onehot = pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    df_all = pd.concat([df.drop([column_name], axis=1), df_onehot], axis=1)\n",
    "    predictors.append(column_name)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def encode_count(df, column_name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(df[column_name].values))\n",
    "    df[column_name] = le.transform(list(df[column_name].values))\n",
    "    predictors.append(column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_count(df, columns_groupby, new_column_name, type='uint64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby).size()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_nunique(df, columns_groupby, column, new_column_name, type='uint64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].nunique()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_cumcount(df, columns_groupby, column, new_column_name, type='uint64'):\n",
    "    df[new_column_name] = df.groupby(columns_groupby)[column].cumcount().values.astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_median(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].median()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_mean(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].mean()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_sum(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].sum()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    # predictors.append(new_column_name)  # bug: twice\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_max(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].max()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_min(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].min()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_std(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].std()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_var(df, columns_groupby, column, new_column_name, type='float64'):\n",
    "    add = pd.DataFrame(df.groupby(columns_groupby)[column].var()).reset_index()\n",
    "    add.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(add, on=columns_groupby, how=\"left\")\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_rank(df, columns_groupby, column, new_column_name, ascending=True, type='uint64'):\n",
    "    df[new_column_name] = df.groupby(columns_groupby)[column].rank(ascending=ascending)\n",
    "    df[new_column_name] = df[new_column_name].astype(type)\n",
    "    predictors.append(new_column_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_count(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_count = pd.DataFrame(df_feat.groupby(columns_groupby)[column].count()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_count.columns = columns_groupby + [column + \"_gb_%s_count\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_count.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_count, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_count.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_nunique(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_nunique = pd.DataFrame(df_feat.groupby(columns_groupby)[column].nunique()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_nunique.columns = columns_groupby + [column + \"_%s_nunique\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_nunique.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_nunique, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_nunique.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_mean(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_mean = pd.DataFrame(df_feat.groupby(columns_groupby)[column].mean()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_mean.columns = columns_groupby + [column + \"_%s_mean\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_mean.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_mean, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_mean.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_std(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_std = pd.DataFrame(df_feat.groupby(columns_groupby)[column].std()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_std.columns = columns_groupby + [column + \"_%s_std\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_std.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_std, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_std.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_median(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_median = pd.DataFrame(df_feat.groupby(columns_groupby)[column].median()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_median.columns = columns_groupby + [column + \"_%s_median\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_median.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_median, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_median.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_max(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_max = pd.DataFrame(df_feat.groupby(columns_groupby)[column].max()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_max.columns = columns_groupby + [column + \"_%s_max\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_max.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_max, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_max.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_min(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_min = pd.DataFrame(df_feat.groupby(columns_groupby)[column].min()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_min.columns = columns_groupby + [column + \"_%s_min\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_min.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_min, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_min.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_sum(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_sum = pd.DataFrame(df_feat.groupby(columns_groupby)[column].sum()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_sum.columns = columns_groupby + [column + \"_%s_sum\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_sum.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_sum, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_sum.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_var(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_var = pd.DataFrame(df_feat.groupby(columns_groupby)[column].var()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_var.columns = columns_groupby + [column + \"_%s_var\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_var.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_var, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_var.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_quantile(df, df_feat, columns_groupby, column, quantile_n, new_column_name=\"\"):\n",
    "    df_quantile = pd.DataFrame(df_feat.groupby(columns_groupby)[column].quantile(quantile_n)).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_quantile.columns = columns_groupby + [column + \"_%s_quantile\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_quantile.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_quantile, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_quantile.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_feat_skew(df, df_feat, columns_groupby, column, new_column_name=\"\"):\n",
    "    df_skew = pd.DataFrame(df_feat.groupby(columns_groupby)[column].skew()).reset_index()\n",
    "    if not new_column_name:\n",
    "        df_skew.columns = columns_groupby + [column + \"_%s_skew\" % (\"_\".join(columns_groupby))]\n",
    "    else:\n",
    "        df_skew.columns = columns_groupby + [new_column_name]\n",
    "    df = df.merge(df_skew, on=columns_groupby, how=\"left\").fillna(0)\n",
    "    predictors.append(df_skew.columns[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_rank_sp(df, feat1, feat2, ascending):\n",
    "    df.sort_values([feat1, feat2], inplace=True, ascending=ascending)\n",
    "    df['rank'] = range(df.shape[0])\n",
    "    min_rank = df.groupby(feat1, as_index=False)['rank'].agg({'min_rank': 'min'})\n",
    "    df = pd.merge(df, min_rank, on=feat1, how='left')\n",
    "    df['rank'] = df['rank'] - df['min_rank']\n",
    "    predictors.append('rank')\n",
    "    del df['min_rank']\n",
    "    return df\n",
    "\n",
    "\n",
    "def log(info):\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + ' ' + str(info))\n",
    "\n",
    "\n",
    "def log_shape(train, test):\n",
    "    log('Train data shape: %s' % str(train.shape))\n",
    "    log('Test data shape: %s' % str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(df):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    df['date'] = pd.to_datetime(df['click_time'], format=format)\n",
    "    df['month'] = df['date'].dt.month.astype('uint8')\n",
    "    df['weekday'] = df['date'].dt.weekday.astype('uint8')\n",
    "    df['day'] = df['date'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['date'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['date'].dt.minute.astype('uint8')\n",
    "    df['second'] = df['date'].dt.second.astype('uint8')\n",
    "    df['tm_hour'] = (df['hour'] + df['minute'] / 60.0).astype('float32')\n",
    "    df['tm_hour_sin'] = (df['tm_hour'].map(lambda x: math.sin((x - 12) / 24 * 2 * math.pi))).astype('float32')\n",
    "    df['tm_hour_cos'] = (df['tm_hour'].map(lambda x: math.cos((x - 12) / 24 * 2 * math.pi))).astype('float32')\n",
    "    del df['click_time']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Construct features function - begin ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtypes = {\n",
    "    'click_id': 'uint32',\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyz = pd.read_csv('train.csv', nrows=1000, header=0, sep=',', dtype=dtypes, usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>tm_hour</th>\n",
       "      <th>tm_hour_sin</th>\n",
       "      <th>tm_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>14.533334</td>\n",
       "      <td>0.615662</td>\n",
       "      <td>0.788011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>14.550000</td>\n",
       "      <td>0.619094</td>\n",
       "      <td>0.785317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>14.566667</td>\n",
       "      <td>0.622515</td>\n",
       "      <td>0.782608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>14.566667</td>\n",
       "      <td>0.622515</td>\n",
       "      <td>0.782608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>0.625923</td>\n",
       "      <td>0.779885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  is_attributed                date  month  \\\n",
       "0   83230    3       1  13      379              0 2017-11-06 14:32:21     11   \n",
       "1   17357    3       1  19      379              0 2017-11-06 14:33:34     11   \n",
       "2   35810    3       1  13      379              0 2017-11-06 14:34:12     11   \n",
       "3   45745   14       1  13      478              0 2017-11-06 14:34:52     11   \n",
       "4  161007    3       1  13      379              0 2017-11-06 14:35:08     11   \n",
       "\n",
       "   weekday  day  hour  minute  second    tm_hour  tm_hour_sin  tm_hour_cos  \n",
       "0        0    6    14      32      21  14.533334     0.615662     0.788011  \n",
       "1        0    6    14      33      34  14.550000     0.619094     0.785317  \n",
       "2        0    6    14      34      12  14.566667     0.622515     0.782608  \n",
       "3        0    6    14      34      52  14.566667     0.622515     0.782608  \n",
       "4        0    6    14      35       8  14.583333     0.625923     0.779885  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyz = process_date(gyz)\n",
    "gyz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaT\n",
       "1          NaT\n",
       "2          NaT\n",
       "3          NaT\n",
       "4          NaT\n",
       "5          NaT\n",
       "6          NaT\n",
       "7          NaT\n",
       "8          NaT\n",
       "9          NaT\n",
       "10         NaT\n",
       "11         NaT\n",
       "12         NaT\n",
       "13         NaT\n",
       "14         NaT\n",
       "15         NaT\n",
       "16         NaT\n",
       "17         NaT\n",
       "18         NaT\n",
       "19         NaT\n",
       "20         NaT\n",
       "21         NaT\n",
       "22         NaT\n",
       "23         NaT\n",
       "24         NaT\n",
       "25         NaT\n",
       "26         NaT\n",
       "27    01:00:48\n",
       "28         NaT\n",
       "29         NaT\n",
       "        ...   \n",
       "970        NaT\n",
       "971        NaT\n",
       "972        NaT\n",
       "973        NaT\n",
       "974        NaT\n",
       "975        NaT\n",
       "976        NaT\n",
       "977        NaT\n",
       "978        NaT\n",
       "979        NaT\n",
       "980        NaT\n",
       "981        NaT\n",
       "982        NaT\n",
       "983        NaT\n",
       "984        NaT\n",
       "985        NaT\n",
       "986        NaT\n",
       "987        NaT\n",
       "988        NaT\n",
       "989        NaT\n",
       "990        NaT\n",
       "991        NaT\n",
       "992        NaT\n",
       "993        NaT\n",
       "994        NaT\n",
       "995        NaT\n",
       "996        NaT\n",
       "997        NaT\n",
       "998        NaT\n",
       "999        NaT\n",
       "Name: date, Length: 1000, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyz[['ip', 'os', 'device', 'app', \"date\"]].groupby(['ip', 'os', 'device', 'app']).date.shift(-1) - gyz.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_next_time_delta(df, suffix, type='float32'):\n",
    "    groupby_columns = [\n",
    "        {'columns': ['ip', 'app', 'channel', 'device', 'os']},\n",
    "        {'columns': ['ip', 'os', 'device']},\n",
    "        {'columns': ['ip', 'os', 'device', 'app']}\n",
    "    ]\n",
    "    #group by ip os device app and date\n",
    "    # Calculate the time to next click for each group\n",
    "    for spec in groupby_columns:\n",
    "        # Name of new feature\n",
    "        new_name = '{}_{}'.format('_'.join(spec['columns']), suffix)\n",
    "        # Unique list of features to select\n",
    "        all_features = spec['columns'] + ['date']\n",
    "        # Run calculation\n",
    "        log('Calculate ' + suffix + '...')\n",
    "        df[new_name] = (df[all_features].groupby(spec['columns']).date.shift(-1) - df.date).dt.seconds.astype(type)\n",
    "        predictors.append(new_name)\n",
    "        gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def cal_prev_time_delta(df, suffix, type='float32'):\n",
    "    groupby_columns = [\n",
    "        {'columns': ['ip', 'channel']},\n",
    "        {'columns': ['ip', 'os']}\n",
    "    ]\n",
    "    # Calculate the time to prev click for each group\n",
    "    for spec in groupby_columns:\n",
    "        # Name of new feature\n",
    "        new_name = '{}_{}'.format('_'.join(spec['columns']), suffix)\n",
    "        # Unique list of features to select\n",
    "        all_features = spec['columns'] + ['date']\n",
    "        # Run calculation\n",
    "        log('Calculate ' + suffix + '...')\n",
    "        df[new_name] = (df.date - df[all_features].groupby(spec['columns']).date.shift(+1)).dt.seconds.astype(type)\n",
    "        predictors.append(new_name)\n",
    "        gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def cal_cvr(train, test, type='float32'):\n",
    "    train['cvr_gb_ip_day_hour'] = 0\n",
    "    train['cvr_gb_ip_app'] = 0\n",
    "    train['cvr_gb_ip_app_os'] = 0\n",
    "\n",
    "    # Define group by list\n",
    "    idh = ['ip', 'day', 'hour']\n",
    "    ia = ['ip', 'app']\n",
    "    iao = ['ip', 'app', 'os']\n",
    "\n",
    "    kf = KFold(train.shape[0], n_folds=5, shuffle=True, random_state=7)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        log('Fold ' + str(i) + ' begin...')\n",
    "\n",
    "        # Divide train/test fold\n",
    "        tr = train.iloc[train_index, :train.shape[1] - 3]\n",
    "        te = train.iloc[test_index, :train.shape[1] - 3]\n",
    "\n",
    "        # Calculate sum of label of train folds\n",
    "        log('Cal sum_label_gb_ip_day_hour')\n",
    "        tr = merge_sum(tr, idh, 'is_attributed', 'sum_label_gb_ip_day_hour')\n",
    "        log('Cal sum_label_gb_ip_app')\n",
    "        tr = merge_sum(tr, ia, 'is_attributed', 'sum_label_gb_ip_app')\n",
    "        log('Cal sum_label_gb_ip_app_os')\n",
    "        tr = merge_sum(tr, iao, 'is_attributed', 'sum_label_gb_ip_app_os')\n",
    "\n",
    "        # Calculate cvr of train folds with using smothing technique\n",
    "        tr['cvr_gb_ip_day_hour'] = GaussianSmoth().update_moment(tr['count_gb_ip_day_hour'], tr['sum_label_gb_ip_day_hour'])\n",
    "        tr['cvr_gb_ip_app'] = GaussianSmoth().update_moment(tr['count_gb_ip_app'], tr['sum_label_gb_ip_app'])\n",
    "        tr['cvr_gb_ip_app_os'] = GaussianSmoth().update_moment(tr['count_gb_ip_app_os'], tr['sum_label_gb_ip_app_os'])\n",
    "\n",
    "        # Merge test fold with cvr features of train folds\n",
    "        te = te.merge(tr[['cvr_gb_ip_day_hour'] + idh].drop_duplicates(subset=idh, keep='first'), on=idh, how='left')\n",
    "        te = te.merge(tr[['cvr_gb_ip_app'] + ia].drop_duplicates(subset=ia, keep='first'), on=ia, how='left')\n",
    "        te = te.merge(tr[['cvr_gb_ip_app_os'] + iao].drop_duplicates(subset=iao, keep='first'), on=iao, how='left')\n",
    "\n",
    "        # Put it in train\n",
    "        train['cvr_gb_ip_day_hour'] += te['cvr_gb_ip_day_hour']\n",
    "        train['cvr_gb_ip_app'] += te['cvr_gb_ip_app']\n",
    "        train['cvr_gb_ip_app_os'] += te['cvr_gb_ip_app_os']\n",
    "\n",
    "        del tr, te\n",
    "        log('Fold ' + str(i) + ' Done!')\n",
    "\n",
    "    # Convert type\n",
    "    train['cvr_gb_ip_day_hour'] = train['cvr_gb_ip_day_hour'].astype(type)\n",
    "    train['cvr_gb_ip_app'] = train['cvr_gb_ip_app'].astype(type)\n",
    "    train['cvr_gb_ip_app_os'] = train['cvr_gb_ip_app_os'].astype(type)\n",
    "\n",
    "    # Merge cvr of train to test\n",
    "    test = test.merge(train[['cvr_gb_ip_day_hour'] + idh].drop_duplicates(subset=idh, keep='first'), on=idh, how='left')\n",
    "    test = test.merge(train[['cvr_gb_ip_app'] + ia].drop_duplicates(subset=ia, keep='first'), on=ia, how='left')\n",
    "    test = test.merge(train[['cvr_gb_ip_app_os'] + iao].drop_duplicates(subset=iao, keep='first'), on=iao, how='left')\n",
    "\n",
    "    predictors.append('cvr_gb_ip_day_hour')\n",
    "    predictors.append('cvr_gb_ip_app')\n",
    "    predictors.append('cvr_gb_ip_app_os')\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Construct features function - end ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spilt_local_train_test(df, train_size, test_size):\n",
    "    local_train = df[:train_size]\n",
    "    local_test = df[train_size:train_size + test_size]\n",
    "    return local_train, local_test\n",
    "\n",
    "\n",
    "def get_model_input_data(train, test, is_local):\n",
    "    feat = ['ip', 'app', 'device', 'os', 'channel', 'hour']\n",
    "    for f in feat:\n",
    "        if f not in predictors:\n",
    "            predictors.append(f)\n",
    "    train_x = train[predictors]\n",
    "    train_y = train.is_attributed.values\n",
    "    if is_local == 1:\n",
    "        test_x = test[train_x.columns.values]\n",
    "        test_y = test.is_attributed.values\n",
    "        return train_x, train_y, test_x, test_y\n",
    "    else:\n",
    "        test_x = test[train_x.columns.values]\n",
    "        return train_x, train_y, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(train_feature, train_label, test_feature, test_label, params, folds, rounds):\n",
    "    start = time.clock()\n",
    "    print(train_feature.columns)\n",
    "    params['scale_pos_weight'] = float(len(train_label[train_label == 0])) / len(train_label[train_label == 1])\n",
    "    dtrain = lgb.Dataset(train_feature, label=train_label, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])\n",
    "    dtest = lgb.Dataset(test_feature, label=test_label, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])\n",
    "    num_round = rounds\n",
    "    print('LightGBM run cv: ' + 'round: ' + str(rounds))\n",
    "    res = lgb.train(params, dtrain, num_round, valid_sets=[dtest], valid_names=['test'], verbose_eval=1, early_stopping_rounds=20)\n",
    "    elapsed = (time.clock() - start)\n",
    "    print('Time used:', elapsed, 's')\n",
    "    return res.best_iteration, res.best_score['test']['auc'], res\n",
    "\n",
    "\n",
    "def lgb_predict(dtrain, test_feature, rounds, params):\n",
    "#     dtrain = lgb.Dataset(train_feature, label=train_label, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])\n",
    "    num_round = rounds\n",
    "    model = lgb.train(params, dtrain, num_round, valid_sets=[dtrain], verbose_eval=1)\n",
    "    predict = model.predict(test_feature)\n",
    "    return model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_result(test_index, pred, name):\n",
    "    result = pd.DataFrame({'click_id': test_index, 'is_attributed': pred})\n",
    "    result.to_csv(name, index=False, sep=',')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmoth(object):\n",
    "    def __init__(self, alpha=0, beta=0):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_moment(self, tries, success):\n",
    "        '''estimate alpha, beta using moment estimation'''\n",
    "        mean, var = self.__compute_moment(tries, success)\n",
    "        self.alpha = (mean + 0.000001) * ((mean + 0.000001) * (1.000001 - mean) / (var + 0.000001) - 1)\n",
    "        self.beta = (1.000001 - mean) * ((mean + 0.000001) * (1.000001 - mean) / (var + 0.000001) - 1)\n",
    "        print(self.alpha, self.beta)\n",
    "        return (self.alpha + success) / (self.alpha + self.beta + tries)\n",
    "\n",
    "    def __compute_moment(self, tries, success):\n",
    "        # Cal mean and variance\n",
    "        '''moment estimation'''\n",
    "        ctr_list = []\n",
    "        mean = (success / tries).mean()\n",
    "        if len(tries) == 1:\n",
    "            var = 0\n",
    "        else:\n",
    "            var = (success / tries).var()\n",
    "        return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Read data ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 15:51:35 Read data...\n",
      "2018-06-28 15:54:16 Read data done!\n",
      "2018-06-28 15:54:16 Train data shape: (184903890, 7)\n",
      "2018-06-28 15:54:16 Test data shape: (57537505, 6)\n"
     ]
    }
   ],
   "source": [
    "log('Read data...')\n",
    "dtypes = {\n",
    "    'click_id': 'uint32',\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}\n",
    "train = pd.read_csv(root_path + 'train.csv', header=0, sep=',', dtype=dtypes, usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed'])\n",
    "test_supplement = pd.read_csv(root_path + 'test_supplement.csv', header=0, sep=',', dtype=dtypes, usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time'])\n",
    "gc.collect()\n",
    "log('Read data done!')\n",
    "log_shape(train, test_supplement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Preprocess ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 15:55:52 Process date...\n",
      "2018-06-28 16:02:23 Process date done!\n",
      "2018-06-28 16:02:23 Train data shape: (184903890, 16)\n",
      "2018-06-28 16:02:23 Test data shape: (57537505, 15)\n"
     ]
    }
   ],
   "source": [
    "log(('Process date...'))\n",
    "train = process_date(train)\n",
    "test_supplement = process_date(test_supplement)\n",
    "gc.collect()\n",
    "log('Process date done!')\n",
    "log_shape(train, test_supplement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Feature engineer ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 16:02:23 Train size:184903890\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train)\n",
    "log('Train size:' + str(train_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 16:02:23 Train append test_supplement...\n",
      "2018-06-28 16:02:51 Train append test_supplement done!\n"
     ]
    }
   ],
   "source": [
    "log('Train append test_supplement...')\n",
    "df = train.append(test_supplement).reset_index(drop=True)\n",
    "del train\n",
    "del test_supplement\n",
    "gc.collect()\n",
    "log('Train append test_supplement done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 16:02:51 Before feature engineer\n",
      "2018-06-28 16:02:51 Num of features: 16\n",
      "2018-06-28 16:02:51 Features: Index(['app', 'channel', 'date', 'day', 'device', 'hour', 'ip',\n",
      "       'is_attributed', 'minute', 'month', 'os', 'second', 'tm_hour',\n",
      "       'tm_hour_cos', 'tm_hour_sin', 'weekday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "log('Before feature engineer')\n",
    "log('Num of features: ' + str(len(df.columns)))\n",
    "log('Features: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 16:02:51 Cal next_time_delta\n",
      "2018-06-28 16:02:51 Calculate next_time_delta...\n",
      "2018-06-28 16:06:26 Calculate next_time_delta...\n",
      "2018-06-28 16:08:04 Calculate next_time_delta...\n",
      "2018-06-28 16:10:39 Cal prev_time_delta\n",
      "2018-06-28 16:10:39 Calculate prev_time_delta...\n",
      "2018-06-28 16:12:43 Calculate prev_time_delta...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log('Cal next_time_delta')\n",
    "df = cal_next_time_delta(df, 'next_time_delta', 'float32')\n",
    "gc.collect()\n",
    "log('Cal prev_time_delta')\n",
    "df = cal_prev_time_delta(df, 'prev_time_delta', 'float32')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 16:18:57 Cal nunique_channel_gb_ip\n",
      "2018-06-28 16:24:54 Cal nunique_app_gb_ip_device_os\n",
      "2018-06-28 16:32:18 Cal nunique_hour_gb_ip_day\n",
      "2018-06-28 16:37:43 Cal nunique_app_gb_ip\n",
      "2018-06-28 16:44:02 Cal nunique_os_gb_ip_app\n",
      "2018-06-28 16:51:35 Cal nunique_device_gb_ip\n",
      "2018-06-28 16:57:13 Cal nunique_channel_gb_app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log('Cal nunique_channel_gb_ip')\n",
    "df = merge_nunique(df, ['ip'], 'channel', 'nunique_channel_gb_ip', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_app_gb_ip_device_os')\n",
    "df = merge_nunique(df, ['ip', 'device', 'os'], 'app', 'nunique_app_gb_ip_device_os', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_hour_gb_ip_day')\n",
    "df = merge_nunique(df, ['ip', 'day'], 'hour', 'nunique_hour_gb_ip_day', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_app_gb_ip')\n",
    "df = merge_nunique(df, ['ip'], 'app', 'nunique_app_gb_ip', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_os_gb_ip_app')\n",
    "df = merge_nunique(df, ['ip', 'app'], 'os', 'nunique_os_gb_ip_app', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_device_gb_ip')\n",
    "df = merge_nunique(df, ['ip'], 'device', 'nunique_device_gb_ip', 'uint32')\n",
    "gc.collect()\n",
    "log('Cal nunique_channel_gb_app')\n",
    "df = merge_nunique(df, ['app'], 'channel', 'nunique_channel_gb_app', 'uint32')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 17:10:51 Cal cumcount_os_gb_ip\n",
      "2018-06-28 17:12:20 Cal cumcount_app_gb_ip_device_os\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log('Cal cumcount_os_gb_ip')\n",
    "df = merge_cumcount(df, ['ip'], 'os', 'cumcount_os_gb_ip', 'uint32');\n",
    "gc.collect()\n",
    "log('Cal cumcount_app_gb_ip_device_os')\n",
    "df = merge_cumcount(df, ['ip', 'device', 'os'], 'app', 'cumcount_app_gb_ip_device_os', 'uint32');\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 17:20:37 Cal count_gb_ip_day_hour\n",
      "2018-06-28 17:25:12 Cal count_gb_ip_app\n",
      "2018-06-28 17:30:51 Cal count_gb_ip_app_os\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log('Cal count_gb_ip_day_hour')\n",
    "df = merge_count(df, ['ip', 'day', 'hour'], 'count_gb_ip_day_hour', 'uint32');\n",
    "gc.collect()\n",
    "log('Cal count_gb_ip_app')\n",
    "df = merge_count(df, ['ip', 'app'], 'count_gb_ip_app', 'uint32');\n",
    "gc.collect()\n",
    "log('Cal count_gb_ip_app_os')\n",
    "df = merge_count(df, ['ip', 'app', 'os'], 'count_gb_ip_app_os', 'uint32');\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 17:40:06 Cal var_day_gb_ip_app_os\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log('Cal var_day_gb_ip_app_os')\n",
    "df = merge_var(df, ['ip', 'app', 'os'], 'day', 'var_day_gb_ip_app_os', 'float32')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 17:47:24 After feature engineer\n",
      "2018-06-28 17:47:24 Num of features: 34\n",
      "2018-06-28 17:47:24 Features: Index(['app', 'channel', 'date', 'day', 'device', 'hour', 'ip',\n",
      "       'is_attributed', 'minute', 'month', 'os', 'second', 'tm_hour',\n",
      "       'tm_hour_cos', 'tm_hour_sin', 'weekday',\n",
      "       'ip_app_channel_device_os_next_time_delta',\n",
      "       'ip_os_device_next_time_delta', 'ip_os_device_app_next_time_delta',\n",
      "       'ip_channel_prev_time_delta', 'ip_os_prev_time_delta',\n",
      "       'nunique_channel_gb_ip', 'nunique_app_gb_ip_device_os',\n",
      "       'nunique_hour_gb_ip_day', 'nunique_app_gb_ip', 'nunique_os_gb_ip_app',\n",
      "       'nunique_device_gb_ip', 'nunique_channel_gb_app', 'cumcount_os_gb_ip',\n",
      "       'cumcount_app_gb_ip_device_os', 'count_gb_ip_day_hour',\n",
      "       'count_gb_ip_app', 'count_gb_ip_app_os', 'var_day_gb_ip_app_os'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "log('After feature engineer')\n",
    "log('Num of features: ' + str(len(df.columns)))\n",
    "log('Features: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(\"chinese_person_model.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open(\"chinese_person_model.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 18:47:50 Train test_supplement divid...\n",
      "2018-06-28 18:48:09 Train data shape: (184903890, 34)\n",
      "2018-06-28 18:48:09 Test data shape: (57537505, 34)\n",
      "2018-06-28 18:48:09 Train test_supplement divid done!\n"
     ]
    }
   ],
   "source": [
    "log('Train test_supplement divid...')\n",
    "train = df[:train_len]\n",
    "test_supplement = df[train_len:]\n",
    "del df\n",
    "gc.collect()\n",
    "log_shape(train, test_supplement)\n",
    "log('Train test_supplement divid done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 18:48:22 Read test...\n",
      "2018-06-28 18:48:42 Test data original shape: (18790469, 7)\n"
     ]
    }
   ],
   "source": [
    "log('Read test...')\n",
    "test = pd.read_csv(root_path + 'test.csv', header=0, sep=',', dtype=dtypes, usecols=['click_id', 'ip', 'app', 'device', 'os', 'channel', 'click_time'], parse_dates=['click_time'])\n",
    "log('Test data original shape: ' + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 18:51:54 Train data shape: (184903890, 34)\n",
      "2018-06-28 18:51:54 Test data shape: (18790469, 35)\n",
      "2018-06-28 18:51:54 Read test done!\n"
     ]
    }
   ],
   "source": [
    "test = test.merge(test_supplement.drop_duplicates(subset=['ip', 'app', 'device', 'os', 'channel', 'date'], keep='first'), left_on=['ip', 'app', 'device', 'os', 'channel', 'click_time'], right_on=['ip', 'app', 'device', 'os', 'channel', 'date'], how='left')\n",
    "test.drop(['click_time'], axis=1, inplace=True)\n",
    "del test_supplement\n",
    "gc.collect()\n",
    "log_shape(train, test)\n",
    "log('Read test done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 18:52:12 Cal cvr...\n",
      "2018-06-28 18:52:36 Fold 0 begin...\n",
      "2018-06-28 18:53:37 Cal sum_label_gb_ip_day_hour\n",
      "2018-06-28 18:56:34 Cal sum_label_gb_ip_app\n",
      "2018-06-28 19:00:02 Cal sum_label_gb_ip_app_os\n",
      "0.0035311148268673486 1.656359258566487\n",
      "0.001306208065960712 0.6615934683856983\n",
      "0.000896427256614664 0.4242455477965775\n",
      "2018-06-28 19:08:39 Fold 0 Done!\n",
      "2018-06-28 19:08:42 Fold 1 begin...\n",
      "2018-06-28 19:09:43 Cal sum_label_gb_ip_day_hour\n",
      "2018-06-28 19:12:43 Cal sum_label_gb_ip_app\n",
      "2018-06-28 19:16:30 Cal sum_label_gb_ip_app_os\n",
      "0.0035423236432704022 1.6610043930628793\n",
      "0.0013066384017462493 0.6614581849267422\n",
      "0.0008975560377448102 0.42456757856918026\n",
      "2018-06-28 19:25:04 Fold 1 Done!\n",
      "2018-06-28 19:25:08 Fold 2 begin...\n",
      "2018-06-28 19:26:06 Cal sum_label_gb_ip_day_hour\n",
      "2018-06-28 19:29:07 Cal sum_label_gb_ip_app\n",
      "2018-06-28 19:32:52 Cal sum_label_gb_ip_app_os\n",
      "0.003544077155657474 1.6644437732869244\n",
      "0.0013067475306259206 0.6628916191252506\n",
      "0.000897447530380914 0.4253481040987524\n",
      "2018-06-28 19:41:18 Fold 2 Done!\n",
      "2018-06-28 19:41:22 Fold 3 begin...\n",
      "2018-06-28 19:42:22 Cal sum_label_gb_ip_day_hour\n",
      "2018-06-28 19:45:22 Cal sum_label_gb_ip_app\n",
      "2018-06-28 19:49:07 Cal sum_label_gb_ip_app_os\n",
      "0.003556694577424439 1.6667865866151168\n",
      "0.0013105256706873155 0.6634791030056233\n",
      "0.0009000090428150375 0.4257430361786561\n",
      "2018-06-28 19:57:36 Fold 3 Done!\n",
      "2018-06-28 19:57:40 Fold 4 begin...\n",
      "2018-06-28 19:58:41 Cal sum_label_gb_ip_day_hour\n",
      "2018-06-28 20:01:41 Cal sum_label_gb_ip_app\n",
      "2018-06-28 20:05:30 Cal sum_label_gb_ip_app_os\n",
      "0.003551481655408224 1.6667515807860234\n",
      "0.0013093233979693153 0.663958115128251\n",
      "0.0008982991130381379 0.42557897784488274\n",
      "2018-06-28 20:13:59 Fold 4 Done!\n",
      "2018-06-28 20:16:16 Cal cvr done!\n"
     ]
    }
   ],
   "source": [
    "log('Cal cvr...')\n",
    "train, test = cal_cvr(train, test, 'float32')\n",
    "log('Cal cvr done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_feats = ['cvr_gb_ip_day_hour', 'cvr_gb_ip_app', 'cvr_gb_ip_app_os']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train[cvr_feats], open('train_cvr.p', 'wb'), protocol=4)\n",
    "pickle.dump(test[cvr_feats], open('test_cvr.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################### Split dataset for local ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 20:18:03 Split dataset to get local train/test set...\n",
      "2018-06-28 20:18:03 Split dataset to get local train/test set done!\n",
      "2018-06-28 20:18:03 ================================= Local data info =====================================\n",
      "2018-06-28 20:18:03 Local train shape:(10000000, 37)\n",
      "2018-06-28 20:18:03 Local test shape:(2500000, 37)\n",
      "2018-06-28 20:18:04 Local train label ratio (0-1):[0.9981283 0.0018717]\n",
      "2018-06-28 20:18:04 Local train label number (0-1):[9981283   18717]\n",
      "2018-06-28 20:18:04 Local train min/max date:2017-11-06 14:32:21,2017-11-07 00:12:03\n",
      "2018-06-28 20:18:04 Local test min/max date:2017-11-07 00:12:03,2017-11-07 00:52:39\n",
      "2018-06-28 20:18:04 =======================================================================================\n",
      "2018-06-28 20:18:04 ================================= Online data info =====================================\n",
      "2018-06-28 20:18:04 Online train shape:(184903890, 37)\n",
      "2018-06-28 20:18:04 Online test shape:(18790469, 38)\n",
      "2018-06-28 20:18:06 Online train label ratio (0-1):[0.99752928 0.00247072]\n",
      "2018-06-28 20:18:07 Online train label number (0-1):[184447044    456846]\n",
      "2018-06-28 20:18:09 Online train min/max date:2017-11-06 14:32:21,2017-11-09 16:00:00\n",
      "2018-06-28 20:18:09 Online train min/max date:2017-11-10 04:00:00,2017-11-10 15:00:00\n",
      "2018-06-28 20:18:09 =======================================================================================\n"
     ]
    }
   ],
   "source": [
    "log('Split dataset to get local train/test set...')\n",
    "local_train_size = 10000000  # 182403890\n",
    "local_test_size = 2500000\n",
    "local_train, local_test = spilt_local_train_test(train, local_train_size, local_test_size)\n",
    "log('Split dataset to get local train/test set done!')\n",
    "\n",
    "log('================================= Local data info =====================================')\n",
    "log('Local train shape:' + str(local_train.shape))\n",
    "log('Local test shape:' + str(local_test.shape))\n",
    "log('Local train label ratio (0-1):' + str(local_train.is_attributed.value_counts().values * 1.0 / local_train.shape[0]))\n",
    "log('Local train label number (0-1):' + str(local_train.is_attributed.value_counts().values))\n",
    "log('Local train min/max date:' + str(local_train.date.min()) + ',' + str(local_train.date.max()))\n",
    "log('Local test min/max date:' + str(local_test.date.min()) + ',' + str(local_test.date.max()))\n",
    "log('=======================================================================================')\n",
    "\n",
    "log('================================= Online data info =====================================')\n",
    "log('Online train shape:' + str(train.shape))\n",
    "log('Online test shape:' + str(test.shape))\n",
    "log('Online train label ratio (0-1):' + str(train.is_attributed.value_counts().values * 1.0 / train.shape[0]))\n",
    "log('Online train label number (0-1):' + str(train.is_attributed.value_counts().values))\n",
    "log('Online train min/max date:' + str(train.date.min()) + ',' + str(train.date.max()))\n",
    "log('Online train min/max date:' + str(test.date.min()) + ',' + str(test.date.max()))\n",
    "log('=======================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 20:18:30 Get local model input data...\n",
      "2018-06-28 20:18:30 Train data shape: (10000000, 27)\n",
      "2018-06-28 20:18:30 Test data shape: (2500000, 27)\n",
      "2018-06-28 20:18:30 Get local model input data done!\n"
     ]
    }
   ],
   "source": [
    "log('Get local model input data...')\n",
    "local_train_x, local_train_y, local_test_x, local_test_y = get_model_input_data(local_train, local_test, is_local=1)\n",
    "del local_train\n",
    "del local_test\n",
    "gc.collect()\n",
    "log_shape(local_train_x, local_test_x)\n",
    "log('Get local model input data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-28 20:18:56 Get online model input data...\n",
      "2018-06-28 20:19:15 Train data shape: (184903890, 27)\n",
      "2018-06-28 20:19:15 Test data shape: (18790469, 27)\n",
      "2018-06-28 20:19:15 Get online model input data done!\n"
     ]
    }
   ],
   "source": [
    "log('Get online model input data...')\n",
    "online_train_x, online_train_y, online_test_x = get_model_input_data(train, test, is_local=0)\n",
    "del train\n",
    "del test\n",
    "gc.collect()\n",
    "log_shape(online_train_x, online_test_x)\n",
    "log('Get online model input data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### LigthGBM ###########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_lgb = {\n",
    "    'rounds': 10000,\n",
    "    'folds': 5\n",
    "}\n",
    "\n",
    "params_lgb = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'xentropy',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.02,\n",
    "    # 'is_unbalance': 'true',  # Because training data is unbalance (replaced with scale_pos_weight)\n",
    "    'scale_pos_weight': 200,  # Because training data is extremely unbalanced\n",
    "    'num_leaves': 31,  # We should let it be smaller than 2^(max_depth)\n",
    "    'max_depth': -1,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 128,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # Frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    'reg_alpha': 0.99,  # L1 regularization term on weights\n",
    "    'reg_lambda': 0.9,  # L2 regularization term on weights\n",
    "    'nthread': 14,\n",
    "    'verbose': 1,\n",
    "    'seed': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ip_app_channel_device_os_next_time_delta',\n",
      "       'ip_os_device_next_time_delta', 'ip_os_device_app_next_time_delta',\n",
      "       'ip_channel_prev_time_delta', 'ip_os_prev_time_delta',\n",
      "       'nunique_channel_gb_ip', 'nunique_app_gb_ip_device_os',\n",
      "       'nunique_hour_gb_ip_day', 'nunique_app_gb_ip', 'nunique_os_gb_ip_app',\n",
      "       'nunique_device_gb_ip', 'nunique_channel_gb_app', 'cumcount_os_gb_ip',\n",
      "       'cumcount_app_gb_ip_device_os', 'count_gb_ip_day_hour',\n",
      "       'count_gb_ip_app', 'count_gb_ip_app_os', 'var_day_gb_ip_app_os',\n",
      "       'cvr_gb_ip_day_hour', 'cvr_gb_ip_app', 'cvr_gb_ip_app_os', 'ip', 'app',\n",
      "       'device', 'os', 'channel', 'hour'],\n",
      "      dtype='object')\n",
      "LightGBM run cv: round: 10000\n",
      "[1]\ttest's auc: 0.903934\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttest's auc: 0.918299\n",
      "[3]\ttest's auc: 0.952441\n",
      "[4]\ttest's auc: 0.953262\n",
      "[5]\ttest's auc: 0.954077\n",
      "[6]\ttest's auc: 0.963225\n",
      "[7]\ttest's auc: 0.963417\n",
      "[8]\ttest's auc: 0.963978\n",
      "[9]\ttest's auc: 0.964701\n",
      "[10]\ttest's auc: 0.965288\n",
      "[11]\ttest's auc: 0.970361\n",
      "[12]\ttest's auc: 0.970434\n",
      "[13]\ttest's auc: 0.970654\n",
      "[14]\ttest's auc: 0.970758\n",
      "[15]\ttest's auc: 0.970783\n",
      "[16]\ttest's auc: 0.970795\n",
      "[17]\ttest's auc: 0.97125\n",
      "[18]\ttest's auc: 0.971316\n",
      "[19]\ttest's auc: 0.971504\n",
      "[20]\ttest's auc: 0.971512\n",
      "[21]\ttest's auc: 0.971512\n",
      "[22]\ttest's auc: 0.971579\n",
      "[23]\ttest's auc: 0.971592\n",
      "[24]\ttest's auc: 0.971577\n",
      "[25]\ttest's auc: 0.971589\n",
      "[26]\ttest's auc: 0.972024\n",
      "[27]\ttest's auc: 0.972006\n",
      "[28]\ttest's auc: 0.972009\n",
      "[29]\ttest's auc: 0.972134\n",
      "[30]\ttest's auc: 0.972205\n",
      "[31]\ttest's auc: 0.972214\n",
      "[32]\ttest's auc: 0.97219\n",
      "[33]\ttest's auc: 0.972386\n",
      "[34]\ttest's auc: 0.972933\n",
      "[35]\ttest's auc: 0.973121\n",
      "[36]\ttest's auc: 0.973178\n",
      "[37]\ttest's auc: 0.973145\n",
      "[38]\ttest's auc: 0.973208\n",
      "[39]\ttest's auc: 0.973164\n",
      "[40]\ttest's auc: 0.97316\n",
      "[41]\ttest's auc: 0.973315\n",
      "[42]\ttest's auc: 0.973348\n",
      "[43]\ttest's auc: 0.973316\n",
      "[44]\ttest's auc: 0.973388\n",
      "[45]\ttest's auc: 0.973374\n",
      "[46]\ttest's auc: 0.973387\n",
      "[47]\ttest's auc: 0.9734\n",
      "[48]\ttest's auc: 0.973356\n",
      "[49]\ttest's auc: 0.973449\n",
      "[50]\ttest's auc: 0.973478\n",
      "[51]\ttest's auc: 0.973577\n",
      "[52]\ttest's auc: 0.973532\n",
      "[53]\ttest's auc: 0.973529\n",
      "[54]\ttest's auc: 0.973541\n",
      "[55]\ttest's auc: 0.973575\n",
      "[56]\ttest's auc: 0.973583\n",
      "[57]\ttest's auc: 0.973594\n",
      "[58]\ttest's auc: 0.973766\n",
      "[59]\ttest's auc: 0.974065\n",
      "[60]\ttest's auc: 0.974192\n",
      "[61]\ttest's auc: 0.974468\n",
      "[62]\ttest's auc: 0.974528\n",
      "[63]\ttest's auc: 0.974529\n",
      "[64]\ttest's auc: 0.974611\n",
      "[65]\ttest's auc: 0.97474\n",
      "[66]\ttest's auc: 0.974854\n",
      "[67]\ttest's auc: 0.974914\n",
      "[68]\ttest's auc: 0.975036\n",
      "[69]\ttest's auc: 0.975058\n",
      "[70]\ttest's auc: 0.975214\n",
      "[71]\ttest's auc: 0.975329\n",
      "[72]\ttest's auc: 0.97539\n",
      "[73]\ttest's auc: 0.975544\n",
      "[74]\ttest's auc: 0.975825\n",
      "[75]\ttest's auc: 0.975912\n",
      "[76]\ttest's auc: 0.975967\n",
      "[77]\ttest's auc: 0.975926\n",
      "[78]\ttest's auc: 0.975982\n",
      "[79]\ttest's auc: 0.976011\n",
      "[80]\ttest's auc: 0.976059\n",
      "[81]\ttest's auc: 0.976105\n",
      "[82]\ttest's auc: 0.976181\n",
      "[83]\ttest's auc: 0.976216\n",
      "[84]\ttest's auc: 0.976238\n",
      "[85]\ttest's auc: 0.976325\n",
      "[86]\ttest's auc: 0.976418\n",
      "[87]\ttest's auc: 0.976437\n",
      "[88]\ttest's auc: 0.976536\n",
      "[89]\ttest's auc: 0.976733\n",
      "[90]\ttest's auc: 0.976722\n",
      "[91]\ttest's auc: 0.97686\n",
      "[92]\ttest's auc: 0.976914\n",
      "[93]\ttest's auc: 0.976924\n",
      "[94]\ttest's auc: 0.976984\n",
      "[95]\ttest's auc: 0.976998\n",
      "[96]\ttest's auc: 0.977079\n",
      "[97]\ttest's auc: 0.977087\n",
      "[98]\ttest's auc: 0.97713\n",
      "[99]\ttest's auc: 0.977139\n",
      "[100]\ttest's auc: 0.977224\n",
      "[101]\ttest's auc: 0.977326\n",
      "[102]\ttest's auc: 0.977398\n",
      "[103]\ttest's auc: 0.97742\n",
      "[104]\ttest's auc: 0.977455\n",
      "[105]\ttest's auc: 0.977543\n",
      "[106]\ttest's auc: 0.977621\n",
      "[107]\ttest's auc: 0.977624\n",
      "[108]\ttest's auc: 0.977614\n",
      "[109]\ttest's auc: 0.97769\n",
      "[110]\ttest's auc: 0.977729\n",
      "[111]\ttest's auc: 0.977769\n",
      "[112]\ttest's auc: 0.977805\n",
      "[113]\ttest's auc: 0.977829\n",
      "[114]\ttest's auc: 0.977903\n",
      "[115]\ttest's auc: 0.977925\n",
      "[116]\ttest's auc: 0.977963\n",
      "[117]\ttest's auc: 0.977958\n",
      "[118]\ttest's auc: 0.978027\n",
      "[119]\ttest's auc: 0.978024\n",
      "[120]\ttest's auc: 0.978026\n",
      "[121]\ttest's auc: 0.978053\n",
      "[122]\ttest's auc: 0.978091\n",
      "[123]\ttest's auc: 0.978116\n",
      "[124]\ttest's auc: 0.978139\n",
      "[125]\ttest's auc: 0.978323\n",
      "[126]\ttest's auc: 0.978344\n",
      "[127]\ttest's auc: 0.978357\n",
      "[128]\ttest's auc: 0.978362\n",
      "[129]\ttest's auc: 0.978503\n",
      "[130]\ttest's auc: 0.978538\n",
      "[131]\ttest's auc: 0.978621\n",
      "[132]\ttest's auc: 0.978662\n",
      "[133]\ttest's auc: 0.978688\n",
      "[134]\ttest's auc: 0.978696\n",
      "[135]\ttest's auc: 0.97873\n",
      "[136]\ttest's auc: 0.978762\n",
      "[137]\ttest's auc: 0.978814\n",
      "[138]\ttest's auc: 0.978836\n",
      "[139]\ttest's auc: 0.978862\n",
      "[140]\ttest's auc: 0.9789\n",
      "[141]\ttest's auc: 0.978931\n",
      "[142]\ttest's auc: 0.978942\n",
      "[143]\ttest's auc: 0.978975\n",
      "[144]\ttest's auc: 0.97899\n",
      "[145]\ttest's auc: 0.979005\n",
      "[146]\ttest's auc: 0.979041\n",
      "[147]\ttest's auc: 0.979059\n",
      "[148]\ttest's auc: 0.97905\n",
      "[149]\ttest's auc: 0.979081\n",
      "[150]\ttest's auc: 0.979113\n",
      "[151]\ttest's auc: 0.979141\n",
      "[152]\ttest's auc: 0.979133\n",
      "[153]\ttest's auc: 0.979146\n",
      "[154]\ttest's auc: 0.979199\n",
      "[155]\ttest's auc: 0.979239\n",
      "[156]\ttest's auc: 0.979241\n",
      "[157]\ttest's auc: 0.97929\n",
      "[158]\ttest's auc: 0.979325\n",
      "[159]\ttest's auc: 0.979338\n",
      "[160]\ttest's auc: 0.979335\n",
      "[161]\ttest's auc: 0.979384\n",
      "[162]\ttest's auc: 0.979382\n",
      "[163]\ttest's auc: 0.979386\n",
      "[164]\ttest's auc: 0.979396\n",
      "[165]\ttest's auc: 0.979398\n",
      "[166]\ttest's auc: 0.979424\n",
      "[167]\ttest's auc: 0.979434\n",
      "[168]\ttest's auc: 0.979475\n",
      "[169]\ttest's auc: 0.97951\n",
      "[170]\ttest's auc: 0.979512\n",
      "[171]\ttest's auc: 0.979496\n",
      "[172]\ttest's auc: 0.979502\n",
      "[173]\ttest's auc: 0.979517\n",
      "[174]\ttest's auc: 0.97956\n",
      "[175]\ttest's auc: 0.979557\n",
      "[176]\ttest's auc: 0.979551\n",
      "[177]\ttest's auc: 0.979548\n",
      "[178]\ttest's auc: 0.979547\n",
      "[179]\ttest's auc: 0.979552\n",
      "[180]\ttest's auc: 0.979561\n",
      "[181]\ttest's auc: 0.979577\n",
      "[182]\ttest's auc: 0.979571\n",
      "[183]\ttest's auc: 0.979586\n",
      "[184]\ttest's auc: 0.979615\n",
      "[185]\ttest's auc: 0.979664\n",
      "[186]\ttest's auc: 0.979699\n",
      "[187]\ttest's auc: 0.979735\n",
      "[188]\ttest's auc: 0.979744\n",
      "[189]\ttest's auc: 0.979754\n",
      "[190]\ttest's auc: 0.979771\n",
      "[191]\ttest's auc: 0.979791\n",
      "[192]\ttest's auc: 0.9798\n",
      "[193]\ttest's auc: 0.979814\n",
      "[194]\ttest's auc: 0.979828\n",
      "[195]\ttest's auc: 0.979866\n",
      "[196]\ttest's auc: 0.979876\n",
      "[197]\ttest's auc: 0.979899\n",
      "[198]\ttest's auc: 0.979914\n",
      "[199]\ttest's auc: 0.979928\n",
      "[200]\ttest's auc: 0.979935\n",
      "[201]\ttest's auc: 0.979963\n",
      "[202]\ttest's auc: 0.979972\n",
      "[203]\ttest's auc: 0.979978\n",
      "[204]\ttest's auc: 0.980018\n",
      "[205]\ttest's auc: 0.980032\n",
      "[206]\ttest's auc: 0.980031\n",
      "[207]\ttest's auc: 0.980049\n",
      "[208]\ttest's auc: 0.980069\n",
      "[209]\ttest's auc: 0.980071\n",
      "[210]\ttest's auc: 0.980077\n",
      "[211]\ttest's auc: 0.980072\n",
      "[212]\ttest's auc: 0.980077\n",
      "[213]\ttest's auc: 0.980085\n",
      "[214]\ttest's auc: 0.980101\n",
      "[215]\ttest's auc: 0.980104\n",
      "[216]\ttest's auc: 0.980119\n",
      "[217]\ttest's auc: 0.980142\n",
      "[218]\ttest's auc: 0.98015\n",
      "[219]\ttest's auc: 0.980158\n",
      "[220]\ttest's auc: 0.980176\n",
      "[221]\ttest's auc: 0.980173\n",
      "[222]\ttest's auc: 0.980181\n",
      "[223]\ttest's auc: 0.980184\n",
      "[224]\ttest's auc: 0.980201\n",
      "[225]\ttest's auc: 0.980214\n",
      "[226]\ttest's auc: 0.980221\n",
      "[227]\ttest's auc: 0.980243\n",
      "[228]\ttest's auc: 0.980257\n",
      "[229]\ttest's auc: 0.980269\n",
      "[230]\ttest's auc: 0.98026\n",
      "[231]\ttest's auc: 0.980296\n",
      "[232]\ttest's auc: 0.980303\n",
      "[233]\ttest's auc: 0.980312\n",
      "[234]\ttest's auc: 0.98032\n",
      "[235]\ttest's auc: 0.980334\n",
      "[236]\ttest's auc: 0.980331\n",
      "[237]\ttest's auc: 0.980326\n",
      "[238]\ttest's auc: 0.980319\n",
      "[239]\ttest's auc: 0.98033\n",
      "[240]\ttest's auc: 0.980347\n",
      "[241]\ttest's auc: 0.98035\n",
      "[242]\ttest's auc: 0.980367\n",
      "[243]\ttest's auc: 0.980371\n",
      "[244]\ttest's auc: 0.980365\n",
      "[245]\ttest's auc: 0.980367\n",
      "[246]\ttest's auc: 0.980365\n",
      "[247]\ttest's auc: 0.980371\n",
      "[248]\ttest's auc: 0.980372\n",
      "[249]\ttest's auc: 0.980381\n",
      "[250]\ttest's auc: 0.980388\n",
      "[251]\ttest's auc: 0.980388\n",
      "[252]\ttest's auc: 0.980394\n",
      "[253]\ttest's auc: 0.980399\n",
      "[254]\ttest's auc: 0.980421\n",
      "[255]\ttest's auc: 0.980436\n",
      "[256]\ttest's auc: 0.980447\n",
      "[257]\ttest's auc: 0.980452\n",
      "[258]\ttest's auc: 0.980468\n",
      "[259]\ttest's auc: 0.980475\n",
      "[260]\ttest's auc: 0.980491\n",
      "[261]\ttest's auc: 0.980496\n",
      "[262]\ttest's auc: 0.980507\n",
      "[263]\ttest's auc: 0.980517\n",
      "[264]\ttest's auc: 0.980531\n",
      "[265]\ttest's auc: 0.980537\n",
      "[266]\ttest's auc: 0.980533\n",
      "[267]\ttest's auc: 0.980534\n",
      "[268]\ttest's auc: 0.98053\n",
      "[269]\ttest's auc: 0.980539\n",
      "[270]\ttest's auc: 0.980555\n",
      "[271]\ttest's auc: 0.980571\n",
      "[272]\ttest's auc: 0.980571\n",
      "[273]\ttest's auc: 0.980574\n",
      "[274]\ttest's auc: 0.980599\n",
      "[275]\ttest's auc: 0.980593\n",
      "[276]\ttest's auc: 0.98059\n",
      "[277]\ttest's auc: 0.980599\n",
      "[278]\ttest's auc: 0.980613\n",
      "[279]\ttest's auc: 0.980622\n",
      "[280]\ttest's auc: 0.980632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281]\ttest's auc: 0.980642\n",
      "[282]\ttest's auc: 0.98064\n",
      "[283]\ttest's auc: 0.98064\n",
      "[284]\ttest's auc: 0.980641\n",
      "[285]\ttest's auc: 0.980648\n",
      "[286]\ttest's auc: 0.980643\n",
      "[287]\ttest's auc: 0.980643\n",
      "[288]\ttest's auc: 0.980642\n",
      "[289]\ttest's auc: 0.980647\n",
      "[290]\ttest's auc: 0.980641\n",
      "[291]\ttest's auc: 0.980645\n",
      "[292]\ttest's auc: 0.980659\n",
      "[293]\ttest's auc: 0.980652\n",
      "[294]\ttest's auc: 0.980671\n",
      "[295]\ttest's auc: 0.980671\n",
      "[296]\ttest's auc: 0.980675\n",
      "[297]\ttest's auc: 0.980674\n",
      "[298]\ttest's auc: 0.980676\n",
      "[299]\ttest's auc: 0.980688\n",
      "[300]\ttest's auc: 0.980705\n",
      "[301]\ttest's auc: 0.980704\n",
      "[302]\ttest's auc: 0.980724\n",
      "[303]\ttest's auc: 0.980736\n",
      "[304]\ttest's auc: 0.980739\n",
      "[305]\ttest's auc: 0.980729\n",
      "[306]\ttest's auc: 0.980736\n",
      "[307]\ttest's auc: 0.980746\n",
      "[308]\ttest's auc: 0.98076\n",
      "[309]\ttest's auc: 0.980752\n",
      "[310]\ttest's auc: 0.980759\n",
      "[311]\ttest's auc: 0.980747\n",
      "[312]\ttest's auc: 0.980754\n",
      "[313]\ttest's auc: 0.980754\n",
      "[314]\ttest's auc: 0.98075\n",
      "[315]\ttest's auc: 0.980747\n",
      "[316]\ttest's auc: 0.980749\n",
      "[317]\ttest's auc: 0.980753\n",
      "[318]\ttest's auc: 0.980763\n",
      "[319]\ttest's auc: 0.980764\n",
      "[320]\ttest's auc: 0.980769\n",
      "[321]\ttest's auc: 0.980777\n",
      "[322]\ttest's auc: 0.980775\n",
      "[323]\ttest's auc: 0.980788\n",
      "[324]\ttest's auc: 0.980798\n",
      "[325]\ttest's auc: 0.9808\n",
      "[326]\ttest's auc: 0.980804\n",
      "[327]\ttest's auc: 0.980806\n",
      "[328]\ttest's auc: 0.980806\n",
      "[329]\ttest's auc: 0.980808\n",
      "[330]\ttest's auc: 0.980807\n",
      "[331]\ttest's auc: 0.980814\n",
      "[332]\ttest's auc: 0.980822\n",
      "[333]\ttest's auc: 0.980831\n",
      "[334]\ttest's auc: 0.980829\n",
      "[335]\ttest's auc: 0.980834\n",
      "[336]\ttest's auc: 0.980834\n",
      "[337]\ttest's auc: 0.980832\n",
      "[338]\ttest's auc: 0.980836\n",
      "[339]\ttest's auc: 0.980826\n",
      "[340]\ttest's auc: 0.980837\n",
      "[341]\ttest's auc: 0.980841\n",
      "[342]\ttest's auc: 0.980863\n",
      "[343]\ttest's auc: 0.980868\n",
      "[344]\ttest's auc: 0.98088\n",
      "[345]\ttest's auc: 0.980885\n",
      "[346]\ttest's auc: 0.980882\n",
      "[347]\ttest's auc: 0.980876\n",
      "[348]\ttest's auc: 0.980881\n",
      "[349]\ttest's auc: 0.980883\n",
      "[350]\ttest's auc: 0.980893\n",
      "[351]\ttest's auc: 0.980891\n",
      "[352]\ttest's auc: 0.980895\n",
      "[353]\ttest's auc: 0.980893\n",
      "[354]\ttest's auc: 0.980895\n",
      "[355]\ttest's auc: 0.980895\n",
      "[356]\ttest's auc: 0.980889\n",
      "[357]\ttest's auc: 0.980889\n",
      "[358]\ttest's auc: 0.980908\n",
      "[359]\ttest's auc: 0.980899\n",
      "[360]\ttest's auc: 0.98089\n",
      "[361]\ttest's auc: 0.980887\n",
      "[362]\ttest's auc: 0.980911\n",
      "[363]\ttest's auc: 0.980922\n",
      "[364]\ttest's auc: 0.98093\n",
      "[365]\ttest's auc: 0.980926\n",
      "[366]\ttest's auc: 0.980937\n",
      "[367]\ttest's auc: 0.98094\n",
      "[368]\ttest's auc: 0.980938\n",
      "[369]\ttest's auc: 0.980929\n",
      "[370]\ttest's auc: 0.980928\n",
      "[371]\ttest's auc: 0.980924\n",
      "[372]\ttest's auc: 0.980941\n",
      "[373]\ttest's auc: 0.980949\n",
      "[374]\ttest's auc: 0.980942\n",
      "[375]\ttest's auc: 0.980964\n",
      "[376]\ttest's auc: 0.980967\n",
      "[377]\ttest's auc: 0.980978\n",
      "[378]\ttest's auc: 0.980997\n",
      "[379]\ttest's auc: 0.980995\n",
      "[380]\ttest's auc: 0.980996\n",
      "[381]\ttest's auc: 0.980995\n",
      "[382]\ttest's auc: 0.980992\n",
      "[383]\ttest's auc: 0.981005\n",
      "[384]\ttest's auc: 0.980994\n",
      "[385]\ttest's auc: 0.980996\n",
      "[386]\ttest's auc: 0.980992\n",
      "[387]\ttest's auc: 0.981\n",
      "[388]\ttest's auc: 0.981004\n",
      "[389]\ttest's auc: 0.981005\n",
      "[390]\ttest's auc: 0.981012\n",
      "[391]\ttest's auc: 0.981015\n",
      "[392]\ttest's auc: 0.981016\n",
      "[393]\ttest's auc: 0.981017\n",
      "[394]\ttest's auc: 0.981009\n",
      "[395]\ttest's auc: 0.981007\n",
      "[396]\ttest's auc: 0.981011\n",
      "[397]\ttest's auc: 0.981009\n",
      "[398]\ttest's auc: 0.98101\n",
      "[399]\ttest's auc: 0.981009\n",
      "[400]\ttest's auc: 0.98101\n",
      "[401]\ttest's auc: 0.981014\n",
      "[402]\ttest's auc: 0.981016\n",
      "[403]\ttest's auc: 0.981008\n",
      "[404]\ttest's auc: 0.981019\n",
      "[405]\ttest's auc: 0.981016\n",
      "[406]\ttest's auc: 0.981024\n",
      "[407]\ttest's auc: 0.981026\n",
      "[408]\ttest's auc: 0.981023\n",
      "[409]\ttest's auc: 0.981031\n",
      "[410]\ttest's auc: 0.981036\n",
      "[411]\ttest's auc: 0.981041\n",
      "[412]\ttest's auc: 0.981041\n",
      "[413]\ttest's auc: 0.981044\n",
      "[414]\ttest's auc: 0.981038\n",
      "[415]\ttest's auc: 0.981038\n",
      "[416]\ttest's auc: 0.981052\n",
      "[417]\ttest's auc: 0.981056\n",
      "[418]\ttest's auc: 0.981056\n",
      "[419]\ttest's auc: 0.981043\n",
      "[420]\ttest's auc: 0.981054\n",
      "[421]\ttest's auc: 0.981079\n",
      "[422]\ttest's auc: 0.981077\n",
      "[423]\ttest's auc: 0.981081\n",
      "[424]\ttest's auc: 0.981076\n",
      "[425]\ttest's auc: 0.981079\n",
      "[426]\ttest's auc: 0.981074\n",
      "[427]\ttest's auc: 0.98107\n",
      "[428]\ttest's auc: 0.98107\n",
      "[429]\ttest's auc: 0.981075\n",
      "[430]\ttest's auc: 0.981072\n",
      "[431]\ttest's auc: 0.981072\n",
      "[432]\ttest's auc: 0.981077\n",
      "[433]\ttest's auc: 0.981078\n",
      "[434]\ttest's auc: 0.981075\n",
      "[435]\ttest's auc: 0.981081\n",
      "[436]\ttest's auc: 0.981087\n",
      "[437]\ttest's auc: 0.981078\n",
      "[438]\ttest's auc: 0.981078\n",
      "[439]\ttest's auc: 0.98107\n",
      "[440]\ttest's auc: 0.981069\n",
      "[441]\ttest's auc: 0.981067\n",
      "[442]\ttest's auc: 0.98107\n",
      "[443]\ttest's auc: 0.981083\n",
      "[444]\ttest's auc: 0.981074\n",
      "[445]\ttest's auc: 0.981081\n",
      "[446]\ttest's auc: 0.981079\n",
      "[447]\ttest's auc: 0.981091\n",
      "[448]\ttest's auc: 0.981094\n",
      "[449]\ttest's auc: 0.981111\n",
      "[450]\ttest's auc: 0.981112\n",
      "[451]\ttest's auc: 0.981125\n",
      "[452]\ttest's auc: 0.98114\n",
      "[453]\ttest's auc: 0.981152\n",
      "[454]\ttest's auc: 0.981157\n",
      "[455]\ttest's auc: 0.981154\n",
      "[456]\ttest's auc: 0.981146\n",
      "[457]\ttest's auc: 0.981138\n",
      "[458]\ttest's auc: 0.981138\n",
      "[459]\ttest's auc: 0.981144\n",
      "[460]\ttest's auc: 0.981144\n",
      "[461]\ttest's auc: 0.981148\n",
      "[462]\ttest's auc: 0.981158\n",
      "[463]\ttest's auc: 0.981157\n",
      "[464]\ttest's auc: 0.981161\n",
      "[465]\ttest's auc: 0.981161\n",
      "[466]\ttest's auc: 0.981153\n",
      "[467]\ttest's auc: 0.981153\n",
      "[468]\ttest's auc: 0.981161\n",
      "[469]\ttest's auc: 0.981164\n",
      "[470]\ttest's auc: 0.981169\n",
      "[471]\ttest's auc: 0.981179\n",
      "[472]\ttest's auc: 0.981178\n",
      "[473]\ttest's auc: 0.981186\n",
      "[474]\ttest's auc: 0.981181\n",
      "[475]\ttest's auc: 0.981178\n",
      "[476]\ttest's auc: 0.981176\n",
      "[477]\ttest's auc: 0.981184\n",
      "[478]\ttest's auc: 0.981184\n",
      "[479]\ttest's auc: 0.981188\n",
      "[480]\ttest's auc: 0.981188\n",
      "[481]\ttest's auc: 0.981187\n",
      "[482]\ttest's auc: 0.981193\n",
      "[483]\ttest's auc: 0.981196\n",
      "[484]\ttest's auc: 0.98119\n",
      "[485]\ttest's auc: 0.981199\n",
      "[486]\ttest's auc: 0.981204\n",
      "[487]\ttest's auc: 0.981202\n",
      "[488]\ttest's auc: 0.981195\n",
      "[489]\ttest's auc: 0.981195\n",
      "[490]\ttest's auc: 0.981203\n",
      "[491]\ttest's auc: 0.981204\n",
      "[492]\ttest's auc: 0.981212\n",
      "[493]\ttest's auc: 0.98121\n",
      "[494]\ttest's auc: 0.981228\n",
      "[495]\ttest's auc: 0.981241\n",
      "[496]\ttest's auc: 0.981251\n",
      "[497]\ttest's auc: 0.981248\n",
      "[498]\ttest's auc: 0.981249\n",
      "[499]\ttest's auc: 0.981252\n",
      "[500]\ttest's auc: 0.981258\n",
      "[501]\ttest's auc: 0.981259\n",
      "[502]\ttest's auc: 0.981255\n",
      "[503]\ttest's auc: 0.981252\n",
      "[504]\ttest's auc: 0.981257\n",
      "[505]\ttest's auc: 0.981255\n",
      "[506]\ttest's auc: 0.981261\n",
      "[507]\ttest's auc: 0.981263\n",
      "[508]\ttest's auc: 0.981259\n",
      "[509]\ttest's auc: 0.981252\n",
      "[510]\ttest's auc: 0.981249\n",
      "[511]\ttest's auc: 0.98125\n",
      "[512]\ttest's auc: 0.981257\n",
      "[513]\ttest's auc: 0.98127\n",
      "[514]\ttest's auc: 0.981283\n",
      "[515]\ttest's auc: 0.981289\n",
      "[516]\ttest's auc: 0.981287\n",
      "[517]\ttest's auc: 0.981293\n",
      "[518]\ttest's auc: 0.981295\n",
      "[519]\ttest's auc: 0.981299\n",
      "[520]\ttest's auc: 0.9813\n",
      "[521]\ttest's auc: 0.981295\n",
      "[522]\ttest's auc: 0.98129\n",
      "[523]\ttest's auc: 0.981296\n",
      "[524]\ttest's auc: 0.981295\n",
      "[525]\ttest's auc: 0.981293\n",
      "[526]\ttest's auc: 0.981295\n",
      "[527]\ttest's auc: 0.981292\n",
      "[528]\ttest's auc: 0.981291\n",
      "[529]\ttest's auc: 0.98129\n",
      "[530]\ttest's auc: 0.981299\n",
      "[531]\ttest's auc: 0.981296\n",
      "[532]\ttest's auc: 0.98129\n",
      "[533]\ttest's auc: 0.981288\n",
      "[534]\ttest's auc: 0.98129\n",
      "[535]\ttest's auc: 0.981287\n",
      "[536]\ttest's auc: 0.981288\n",
      "[537]\ttest's auc: 0.981292\n",
      "[538]\ttest's auc: 0.981294\n",
      "[539]\ttest's auc: 0.981301\n",
      "[540]\ttest's auc: 0.9813\n",
      "[541]\ttest's auc: 0.981293\n",
      "[542]\ttest's auc: 0.981299\n",
      "[543]\ttest's auc: 0.981292\n",
      "[544]\ttest's auc: 0.981288\n",
      "[545]\ttest's auc: 0.981282\n",
      "[546]\ttest's auc: 0.981281\n",
      "[547]\ttest's auc: 0.981294\n",
      "[548]\ttest's auc: 0.981304\n",
      "[549]\ttest's auc: 0.981312\n",
      "[550]\ttest's auc: 0.981312\n",
      "[551]\ttest's auc: 0.981304\n",
      "[552]\ttest's auc: 0.981316\n",
      "[553]\ttest's auc: 0.981326\n",
      "[554]\ttest's auc: 0.981316\n",
      "[555]\ttest's auc: 0.981325\n",
      "[556]\ttest's auc: 0.981322\n",
      "[557]\ttest's auc: 0.981324\n",
      "[558]\ttest's auc: 0.981335\n",
      "[559]\ttest's auc: 0.981341\n",
      "[560]\ttest's auc: 0.981348\n",
      "[561]\ttest's auc: 0.981356\n",
      "[562]\ttest's auc: 0.981356\n",
      "[563]\ttest's auc: 0.981353\n",
      "[564]\ttest's auc: 0.981356\n",
      "[565]\ttest's auc: 0.981362\n",
      "[566]\ttest's auc: 0.981362\n",
      "[567]\ttest's auc: 0.98136\n",
      "[568]\ttest's auc: 0.981357\n",
      "[569]\ttest's auc: 0.981363\n",
      "[570]\ttest's auc: 0.98137\n",
      "[571]\ttest's auc: 0.981365\n",
      "[572]\ttest's auc: 0.981367\n",
      "[573]\ttest's auc: 0.981364\n",
      "[574]\ttest's auc: 0.981372\n",
      "[575]\ttest's auc: 0.981371\n",
      "[576]\ttest's auc: 0.981376\n",
      "[577]\ttest's auc: 0.981387\n",
      "[578]\ttest's auc: 0.981385\n",
      "[579]\ttest's auc: 0.98138\n",
      "[580]\ttest's auc: 0.981381\n",
      "[581]\ttest's auc: 0.981388\n",
      "[582]\ttest's auc: 0.981385\n",
      "[583]\ttest's auc: 0.981391\n",
      "[584]\ttest's auc: 0.981395\n",
      "[585]\ttest's auc: 0.981404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586]\ttest's auc: 0.981401\n",
      "[587]\ttest's auc: 0.981402\n",
      "[588]\ttest's auc: 0.981404\n",
      "[589]\ttest's auc: 0.981406\n",
      "[590]\ttest's auc: 0.981399\n",
      "[591]\ttest's auc: 0.9814\n",
      "[592]\ttest's auc: 0.981402\n",
      "[593]\ttest's auc: 0.981406\n",
      "[594]\ttest's auc: 0.981404\n",
      "[595]\ttest's auc: 0.981398\n",
      "[596]\ttest's auc: 0.981404\n",
      "[597]\ttest's auc: 0.98141\n",
      "[598]\ttest's auc: 0.981418\n",
      "[599]\ttest's auc: 0.981413\n",
      "[600]\ttest's auc: 0.981415\n",
      "[601]\ttest's auc: 0.981424\n",
      "[602]\ttest's auc: 0.981429\n",
      "[603]\ttest's auc: 0.981417\n",
      "[604]\ttest's auc: 0.981411\n",
      "[605]\ttest's auc: 0.981409\n",
      "[606]\ttest's auc: 0.981402\n",
      "[607]\ttest's auc: 0.981398\n",
      "[608]\ttest's auc: 0.981404\n",
      "[609]\ttest's auc: 0.981405\n",
      "[610]\ttest's auc: 0.981405\n",
      "[611]\ttest's auc: 0.981403\n",
      "[612]\ttest's auc: 0.981402\n",
      "[613]\ttest's auc: 0.981406\n",
      "[614]\ttest's auc: 0.981406\n",
      "[615]\ttest's auc: 0.98141\n",
      "[616]\ttest's auc: 0.98141\n",
      "[617]\ttest's auc: 0.981411\n",
      "[618]\ttest's auc: 0.981415\n",
      "[619]\ttest's auc: 0.981412\n",
      "[620]\ttest's auc: 0.981412\n",
      "[621]\ttest's auc: 0.981423\n",
      "[622]\ttest's auc: 0.981423\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttest's auc: 0.981429\n",
      "Time used: 5737.73515 s\n"
     ]
    }
   ],
   "source": [
    "iterations_lgb, best_score_lgb, model_cv_lgb = lgb_cv(local_train_x, local_train_y, local_test_x, local_test_y, params_lgb, config_lgb['folds'], config_lgb['rounds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                                       6847940240\n",
       "ip_app_channel_device_os_next_time_delta     739615560\n",
       "ip_os_device_next_time_delta                 739615560\n",
       "ip_os_device_app_next_time_delta             739615560\n",
       "ip_channel_prev_time_delta                   739615560\n",
       "ip_os_prev_time_delta                        739615560\n",
       "nunique_channel_gb_ip                        739615560\n",
       "nunique_app_gb_ip_device_os                  739615560\n",
       "nunique_hour_gb_ip_day                       739615560\n",
       "nunique_app_gb_ip                            739615560\n",
       "nunique_os_gb_ip_app                         739615560\n",
       "nunique_device_gb_ip                         739615560\n",
       "nunique_channel_gb_app                       739615560\n",
       "cumcount_os_gb_ip                            739615560\n",
       "cumcount_app_gb_ip_device_os                 739615560\n",
       "count_gb_ip_day_hour                         739615560\n",
       "count_gb_ip_app                              739615560\n",
       "count_gb_ip_app_os                           739615560\n",
       "var_day_gb_ip_app_os                         739615560\n",
       "cvr_gb_ip_day_hour                           739615560\n",
       "cvr_gb_ip_app                                739615560\n",
       "cvr_gb_ip_app_os                             739615560\n",
       "ip                                           739615560\n",
       "app                                          369807780\n",
       "device                                       369807780\n",
       "os                                           369807780\n",
       "channel                                      369807780\n",
       "hour                                         184903890\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_train_x.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb = model_cv_lgb.predict(online_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_column = online_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(online_train_x, open(\"online_train_x.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(online_train_y, open(\"online_train_y.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(iterations_lgb, open(\"iterations_lgb.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(params_lgb, open(\"params_lgb.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(online_test_x, open(\"online_test_x.pickle\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(online_train_x, label=online_train_y, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])\n",
    "del dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-188050f02cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_lgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-cf223963165a>\u001b[0m in \u001b[0;36mlgb_predict\u001b[0;34m(dtrain, test_feature, rounds, params)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     dtrain = lgb.Dataset(train_feature, label=train_label, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1307\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_lgb, pred_lgb = lgb_predict(dtrain, online_test_x, iterations_lgb, params_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgb = sorted(zip(online_train_x.columns, model_cv_lgb.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True)\n",
    "importance_lgb = pd.DataFrame({'feature': importance_lgb})\n",
    "importance_lgb = importance_lgb.apply(lambda x: pd.Series(x['feature']), axis=1)\n",
    "importance_lgb.columns = ['feature', 'importance']\n",
    "importance_lgb.to_csv('importance-lgb-20180507-%f(r%d).csv' % (best_score_lgb, iterations_lgb), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_train_x2 = pickle.load(open(\"online_train_x.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_train_y2 = pickle.load(open(\"online_train_y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(online_train_y2) == len(online_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_lgb2 = pickle.load(open(\"iterations_lgb.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb2 = pickle.load(open(\"params_lgb.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_test_x2 = pickle.load(open(\"online_test_x.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(online_train_x2, label=online_train_y2, categorical_feature=['app', 'device', 'os', 'channel', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.890661\n",
      "[2]\ttraining's auc: 0.926717\n",
      "[3]\ttraining's auc: 0.955742\n",
      "[4]\ttraining's auc: 0.958631\n",
      "[5]\ttraining's auc: 0.959335\n",
      "[6]\ttraining's auc: 0.959503\n",
      "[7]\ttraining's auc: 0.959542\n",
      "[8]\ttraining's auc: 0.959803\n",
      "[9]\ttraining's auc: 0.95994\n",
      "[10]\ttraining's auc: 0.96001\n",
      "[11]\ttraining's auc: 0.960017\n",
      "[12]\ttraining's auc: 0.960142\n",
      "[13]\ttraining's auc: 0.968521\n",
      "[14]\ttraining's auc: 0.96854\n",
      "[15]\ttraining's auc: 0.968633\n",
      "[16]\ttraining's auc: 0.968645\n",
      "[17]\ttraining's auc: 0.968735\n",
      "[18]\ttraining's auc: 0.968795\n",
      "[19]\ttraining's auc: 0.968817\n",
      "[20]\ttraining's auc: 0.968905\n",
      "[21]\ttraining's auc: 0.968916\n",
      "[22]\ttraining's auc: 0.969819\n",
      "[23]\ttraining's auc: 0.969864\n",
      "[24]\ttraining's auc: 0.970065\n",
      "[25]\ttraining's auc: 0.970237\n",
      "[26]\ttraining's auc: 0.970325\n",
      "[27]\ttraining's auc: 0.970521\n",
      "[28]\ttraining's auc: 0.970579\n",
      "[29]\ttraining's auc: 0.970889\n",
      "[30]\ttraining's auc: 0.970928\n",
      "[31]\ttraining's auc: 0.970821\n",
      "[32]\ttraining's auc: 0.971136\n",
      "[33]\ttraining's auc: 0.971192\n",
      "[34]\ttraining's auc: 0.972053\n",
      "[35]\ttraining's auc: 0.972636\n",
      "[36]\ttraining's auc: 0.973034\n",
      "[37]\ttraining's auc: 0.973055\n",
      "[38]\ttraining's auc: 0.973091\n",
      "[39]\ttraining's auc: 0.973145\n",
      "[40]\ttraining's auc: 0.973232\n",
      "[41]\ttraining's auc: 0.97377\n",
      "[42]\ttraining's auc: 0.973793\n",
      "[43]\ttraining's auc: 0.973872\n",
      "[44]\ttraining's auc: 0.973909\n",
      "[45]\ttraining's auc: 0.97422\n",
      "[46]\ttraining's auc: 0.974268\n",
      "[47]\ttraining's auc: 0.974263\n",
      "[48]\ttraining's auc: 0.974287\n",
      "[49]\ttraining's auc: 0.974334\n",
      "[50]\ttraining's auc: 0.974479\n",
      "[51]\ttraining's auc: 0.974753\n",
      "[52]\ttraining's auc: 0.974763\n",
      "[53]\ttraining's auc: 0.974792\n",
      "[54]\ttraining's auc: 0.974845\n",
      "[55]\ttraining's auc: 0.974855\n",
      "[56]\ttraining's auc: 0.974918\n",
      "[57]\ttraining's auc: 0.974936\n",
      "[58]\ttraining's auc: 0.975047\n",
      "[59]\ttraining's auc: 0.975497\n",
      "[60]\ttraining's auc: 0.975511\n",
      "[61]\ttraining's auc: 0.97553\n",
      "[62]\ttraining's auc: 0.975642\n",
      "[63]\ttraining's auc: 0.97586\n",
      "[64]\ttraining's auc: 0.975915\n",
      "[65]\ttraining's auc: 0.975967\n",
      "[66]\ttraining's auc: 0.976001\n",
      "[67]\ttraining's auc: 0.976133\n",
      "[68]\ttraining's auc: 0.976206\n",
      "[69]\ttraining's auc: 0.97623\n",
      "[70]\ttraining's auc: 0.976292\n",
      "[71]\ttraining's auc: 0.976365\n",
      "[72]\ttraining's auc: 0.976478\n",
      "[73]\ttraining's auc: 0.976493\n",
      "[74]\ttraining's auc: 0.976497\n",
      "[75]\ttraining's auc: 0.976541\n",
      "[76]\ttraining's auc: 0.97659\n",
      "[77]\ttraining's auc: 0.976615\n",
      "[78]\ttraining's auc: 0.976635\n",
      "[79]\ttraining's auc: 0.976703\n",
      "[80]\ttraining's auc: 0.976732\n",
      "[81]\ttraining's auc: 0.976745\n",
      "[82]\ttraining's auc: 0.976811\n",
      "[83]\ttraining's auc: 0.976896\n",
      "[84]\ttraining's auc: 0.976905\n",
      "[85]\ttraining's auc: 0.976954\n",
      "[86]\ttraining's auc: 0.976951\n",
      "[87]\ttraining's auc: 0.977053\n",
      "[88]\ttraining's auc: 0.977105\n",
      "[89]\ttraining's auc: 0.977157\n",
      "[90]\ttraining's auc: 0.977219\n",
      "[91]\ttraining's auc: 0.977289\n",
      "[92]\ttraining's auc: 0.977333\n",
      "[93]\ttraining's auc: 0.97742\n",
      "[94]\ttraining's auc: 0.977393\n",
      "[95]\ttraining's auc: 0.977492\n",
      "[96]\ttraining's auc: 0.977562\n",
      "[97]\ttraining's auc: 0.977612\n",
      "[98]\ttraining's auc: 0.977646\n",
      "[99]\ttraining's auc: 0.977679\n",
      "[100]\ttraining's auc: 0.977745\n",
      "[101]\ttraining's auc: 0.977785\n",
      "[102]\ttraining's auc: 0.977762\n",
      "[103]\ttraining's auc: 0.977849\n",
      "[104]\ttraining's auc: 0.977967\n",
      "[105]\ttraining's auc: 0.977855\n",
      "[106]\ttraining's auc: 0.977837\n",
      "[107]\ttraining's auc: 0.977875\n",
      "[108]\ttraining's auc: 0.97806\n",
      "[109]\ttraining's auc: 0.97806\n",
      "[110]\ttraining's auc: 0.978127\n",
      "[111]\ttraining's auc: 0.978191\n",
      "[112]\ttraining's auc: 0.978245\n",
      "[113]\ttraining's auc: 0.978323\n",
      "[114]\ttraining's auc: 0.978358\n",
      "[115]\ttraining's auc: 0.9784\n",
      "[116]\ttraining's auc: 0.978436\n",
      "[117]\ttraining's auc: 0.978447\n",
      "[118]\ttraining's auc: 0.978453\n",
      "[119]\ttraining's auc: 0.978448\n",
      "[120]\ttraining's auc: 0.978463\n",
      "[121]\ttraining's auc: 0.978515\n",
      "[122]\ttraining's auc: 0.978546\n",
      "[123]\ttraining's auc: 0.97866\n",
      "[124]\ttraining's auc: 0.978686\n",
      "[125]\ttraining's auc: 0.978789\n",
      "[126]\ttraining's auc: 0.978826\n",
      "[127]\ttraining's auc: 0.978852\n",
      "[128]\ttraining's auc: 0.978888\n",
      "[129]\ttraining's auc: 0.979007\n",
      "[130]\ttraining's auc: 0.979071\n",
      "[131]\ttraining's auc: 0.97909\n",
      "[132]\ttraining's auc: 0.979134\n",
      "[133]\ttraining's auc: 0.979136\n",
      "[134]\ttraining's auc: 0.979158\n",
      "[135]\ttraining's auc: 0.979215\n",
      "[136]\ttraining's auc: 0.979267\n",
      "[137]\ttraining's auc: 0.97929\n",
      "[138]\ttraining's auc: 0.97933\n",
      "[139]\ttraining's auc: 0.979397\n",
      "[140]\ttraining's auc: 0.979406\n",
      "[141]\ttraining's auc: 0.979453\n",
      "[142]\ttraining's auc: 0.979495\n",
      "[143]\ttraining's auc: 0.979563\n",
      "[144]\ttraining's auc: 0.979595\n",
      "[145]\ttraining's auc: 0.979638\n",
      "[146]\ttraining's auc: 0.979687\n",
      "[147]\ttraining's auc: 0.97973\n",
      "[148]\ttraining's auc: 0.979764\n",
      "[149]\ttraining's auc: 0.97978\n",
      "[150]\ttraining's auc: 0.979839\n",
      "[151]\ttraining's auc: 0.979886\n",
      "[152]\ttraining's auc: 0.979884\n",
      "[153]\ttraining's auc: 0.979923\n",
      "[154]\ttraining's auc: 0.979979\n",
      "[155]\ttraining's auc: 0.980028\n",
      "[156]\ttraining's auc: 0.980024\n",
      "[157]\ttraining's auc: 0.980069\n",
      "[158]\ttraining's auc: 0.980108\n",
      "[159]\ttraining's auc: 0.980137\n",
      "[160]\ttraining's auc: 0.980177\n",
      "[161]\ttraining's auc: 0.980208\n",
      "[162]\ttraining's auc: 0.980203\n",
      "[163]\ttraining's auc: 0.98025\n",
      "[164]\ttraining's auc: 0.980277\n",
      "[165]\ttraining's auc: 0.980314\n",
      "[166]\ttraining's auc: 0.980346\n",
      "[167]\ttraining's auc: 0.980397\n",
      "[168]\ttraining's auc: 0.980443\n",
      "[169]\ttraining's auc: 0.980512\n",
      "[170]\ttraining's auc: 0.980543\n",
      "[171]\ttraining's auc: 0.980581\n",
      "[172]\ttraining's auc: 0.980589\n",
      "[173]\ttraining's auc: 0.98062\n",
      "[174]\ttraining's auc: 0.980657\n",
      "[175]\ttraining's auc: 0.980697\n",
      "[176]\ttraining's auc: 0.980735\n",
      "[177]\ttraining's auc: 0.980766\n",
      "[178]\ttraining's auc: 0.980808\n",
      "[179]\ttraining's auc: 0.980847\n",
      "[180]\ttraining's auc: 0.980863\n",
      "[181]\ttraining's auc: 0.980873\n",
      "[182]\ttraining's auc: 0.980914\n",
      "[183]\ttraining's auc: 0.980948\n",
      "[184]\ttraining's auc: 0.980982\n",
      "[185]\ttraining's auc: 0.981002\n",
      "[186]\ttraining's auc: 0.981012\n",
      "[187]\ttraining's auc: 0.981047\n",
      "[188]\ttraining's auc: 0.98107\n",
      "[189]\ttraining's auc: 0.98109\n",
      "[190]\ttraining's auc: 0.98112\n",
      "[191]\ttraining's auc: 0.981139\n",
      "[192]\ttraining's auc: 0.981171\n",
      "[193]\ttraining's auc: 0.98121\n",
      "[194]\ttraining's auc: 0.981243\n",
      "[195]\ttraining's auc: 0.981268\n",
      "[196]\ttraining's auc: 0.9813\n",
      "[197]\ttraining's auc: 0.981324\n",
      "[198]\ttraining's auc: 0.981362\n",
      "[199]\ttraining's auc: 0.981386\n",
      "[200]\ttraining's auc: 0.981401\n",
      "[201]\ttraining's auc: 0.981421\n",
      "[202]\ttraining's auc: 0.981453\n",
      "[203]\ttraining's auc: 0.981473\n",
      "[204]\ttraining's auc: 0.981495\n",
      "[205]\ttraining's auc: 0.98152\n",
      "[206]\ttraining's auc: 0.981536\n",
      "[207]\ttraining's auc: 0.981556\n",
      "[208]\ttraining's auc: 0.981565\n",
      "[209]\ttraining's auc: 0.981579\n",
      "[210]\ttraining's auc: 0.981599\n",
      "[211]\ttraining's auc: 0.981609\n",
      "[212]\ttraining's auc: 0.981627\n",
      "[213]\ttraining's auc: 0.98165\n",
      "[214]\ttraining's auc: 0.981672\n",
      "[215]\ttraining's auc: 0.98169\n",
      "[216]\ttraining's auc: 0.981711\n",
      "[217]\ttraining's auc: 0.981732\n",
      "[218]\ttraining's auc: 0.98175\n",
      "[219]\ttraining's auc: 0.981769\n",
      "[220]\ttraining's auc: 0.9818\n",
      "[221]\ttraining's auc: 0.981825\n",
      "[222]\ttraining's auc: 0.98184\n",
      "[223]\ttraining's auc: 0.981868\n",
      "[224]\ttraining's auc: 0.981892\n",
      "[225]\ttraining's auc: 0.98192\n",
      "[226]\ttraining's auc: 0.981946\n",
      "[227]\ttraining's auc: 0.981965\n",
      "[228]\ttraining's auc: 0.981999\n",
      "[229]\ttraining's auc: 0.982017\n",
      "[230]\ttraining's auc: 0.982043\n",
      "[231]\ttraining's auc: 0.982069\n",
      "[232]\ttraining's auc: 0.982092\n",
      "[233]\ttraining's auc: 0.982117\n",
      "[234]\ttraining's auc: 0.982132\n",
      "[235]\ttraining's auc: 0.98215\n",
      "[236]\ttraining's auc: 0.982167\n",
      "[237]\ttraining's auc: 0.982196\n",
      "[238]\ttraining's auc: 0.982208\n",
      "[239]\ttraining's auc: 0.982228\n",
      "[240]\ttraining's auc: 0.982246\n",
      "[241]\ttraining's auc: 0.982263\n",
      "[242]\ttraining's auc: 0.982292\n",
      "[243]\ttraining's auc: 0.982317\n",
      "[244]\ttraining's auc: 0.982342\n",
      "[245]\ttraining's auc: 0.982373\n",
      "[246]\ttraining's auc: 0.982392\n",
      "[247]\ttraining's auc: 0.982413\n",
      "[248]\ttraining's auc: 0.982425\n",
      "[249]\ttraining's auc: 0.982453\n",
      "[250]\ttraining's auc: 0.98247\n",
      "[251]\ttraining's auc: 0.982498\n",
      "[252]\ttraining's auc: 0.982516\n",
      "[253]\ttraining's auc: 0.982532\n",
      "[254]\ttraining's auc: 0.98255\n",
      "[255]\ttraining's auc: 0.982571\n",
      "[256]\ttraining's auc: 0.982588\n",
      "[257]\ttraining's auc: 0.982598\n",
      "[258]\ttraining's auc: 0.982628\n",
      "[259]\ttraining's auc: 0.982651\n",
      "[260]\ttraining's auc: 0.98267\n",
      "[261]\ttraining's auc: 0.982683\n",
      "[262]\ttraining's auc: 0.982698\n",
      "[263]\ttraining's auc: 0.982717\n",
      "[264]\ttraining's auc: 0.98273\n",
      "[265]\ttraining's auc: 0.982752\n",
      "[266]\ttraining's auc: 0.982771\n",
      "[267]\ttraining's auc: 0.982791\n",
      "[268]\ttraining's auc: 0.982819\n",
      "[269]\ttraining's auc: 0.982835\n",
      "[270]\ttraining's auc: 0.982849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[271]\ttraining's auc: 0.982862\n",
      "[272]\ttraining's auc: 0.982879\n",
      "[273]\ttraining's auc: 0.982898\n",
      "[274]\ttraining's auc: 0.982918\n",
      "[275]\ttraining's auc: 0.982931\n",
      "[276]\ttraining's auc: 0.982946\n",
      "[277]\ttraining's auc: 0.982965\n",
      "[278]\ttraining's auc: 0.982983\n",
      "[279]\ttraining's auc: 0.983002\n",
      "[280]\ttraining's auc: 0.983021\n",
      "[281]\ttraining's auc: 0.983039\n",
      "[282]\ttraining's auc: 0.983047\n",
      "[283]\ttraining's auc: 0.983066\n",
      "[284]\ttraining's auc: 0.983082\n",
      "[285]\ttraining's auc: 0.9831\n",
      "[286]\ttraining's auc: 0.983121\n",
      "[287]\ttraining's auc: 0.983141\n",
      "[288]\ttraining's auc: 0.983161\n",
      "[289]\ttraining's auc: 0.983174\n",
      "[290]\ttraining's auc: 0.983183\n",
      "[291]\ttraining's auc: 0.98319\n",
      "[292]\ttraining's auc: 0.983204\n",
      "[293]\ttraining's auc: 0.983219\n",
      "[294]\ttraining's auc: 0.983232\n",
      "[295]\ttraining's auc: 0.983243\n",
      "[296]\ttraining's auc: 0.983254\n",
      "[297]\ttraining's auc: 0.983267\n",
      "[298]\ttraining's auc: 0.983284\n",
      "[299]\ttraining's auc: 0.983297\n",
      "[300]\ttraining's auc: 0.983312\n",
      "[301]\ttraining's auc: 0.983326\n",
      "[302]\ttraining's auc: 0.983344\n",
      "[303]\ttraining's auc: 0.983353\n",
      "[304]\ttraining's auc: 0.983363\n",
      "[305]\ttraining's auc: 0.983371\n",
      "[306]\ttraining's auc: 0.983376\n",
      "[307]\ttraining's auc: 0.983389\n",
      "[308]\ttraining's auc: 0.983397\n",
      "[309]\ttraining's auc: 0.983415\n",
      "[310]\ttraining's auc: 0.983428\n",
      "[311]\ttraining's auc: 0.983444\n",
      "[312]\ttraining's auc: 0.983452\n",
      "[313]\ttraining's auc: 0.983456\n",
      "[314]\ttraining's auc: 0.983471\n",
      "[315]\ttraining's auc: 0.983481\n",
      "[316]\ttraining's auc: 0.983494\n",
      "[317]\ttraining's auc: 0.983504\n",
      "[318]\ttraining's auc: 0.983514\n",
      "[319]\ttraining's auc: 0.983527\n",
      "[320]\ttraining's auc: 0.98353\n",
      "[321]\ttraining's auc: 0.98354\n",
      "[322]\ttraining's auc: 0.983546\n",
      "[323]\ttraining's auc: 0.983553\n",
      "[324]\ttraining's auc: 0.983559\n",
      "[325]\ttraining's auc: 0.983569\n",
      "[326]\ttraining's auc: 0.983576\n",
      "[327]\ttraining's auc: 0.983581\n",
      "[328]\ttraining's auc: 0.983592\n",
      "[329]\ttraining's auc: 0.983599\n",
      "[330]\ttraining's auc: 0.983607\n",
      "[331]\ttraining's auc: 0.983614\n",
      "[332]\ttraining's auc: 0.98362\n",
      "[333]\ttraining's auc: 0.983635\n",
      "[334]\ttraining's auc: 0.983649\n",
      "[335]\ttraining's auc: 0.983656\n",
      "[336]\ttraining's auc: 0.983661\n",
      "[337]\ttraining's auc: 0.983665\n",
      "[338]\ttraining's auc: 0.983671\n",
      "[339]\ttraining's auc: 0.983682\n",
      "[340]\ttraining's auc: 0.983691\n",
      "[341]\ttraining's auc: 0.983703\n",
      "[342]\ttraining's auc: 0.983717\n",
      "[343]\ttraining's auc: 0.983727\n",
      "[344]\ttraining's auc: 0.983737\n",
      "[345]\ttraining's auc: 0.983743\n",
      "[346]\ttraining's auc: 0.983748\n",
      "[347]\ttraining's auc: 0.98376\n",
      "[348]\ttraining's auc: 0.983767\n",
      "[349]\ttraining's auc: 0.983776\n",
      "[350]\ttraining's auc: 0.983783\n",
      "[351]\ttraining's auc: 0.983788\n",
      "[352]\ttraining's auc: 0.983796\n",
      "[353]\ttraining's auc: 0.983803\n",
      "[354]\ttraining's auc: 0.983812\n",
      "[355]\ttraining's auc: 0.983818\n",
      "[356]\ttraining's auc: 0.983832\n",
      "[357]\ttraining's auc: 0.983842\n",
      "[358]\ttraining's auc: 0.983846\n",
      "[359]\ttraining's auc: 0.983851\n",
      "[360]\ttraining's auc: 0.983862\n",
      "[361]\ttraining's auc: 0.983868\n",
      "[362]\ttraining's auc: 0.983877\n",
      "[363]\ttraining's auc: 0.98389\n",
      "[364]\ttraining's auc: 0.983899\n",
      "[365]\ttraining's auc: 0.983908\n",
      "[366]\ttraining's auc: 0.983915\n",
      "[367]\ttraining's auc: 0.983918\n",
      "[368]\ttraining's auc: 0.98392\n",
      "[369]\ttraining's auc: 0.983928\n",
      "[370]\ttraining's auc: 0.983937\n",
      "[371]\ttraining's auc: 0.983945\n",
      "[372]\ttraining's auc: 0.983956\n",
      "[373]\ttraining's auc: 0.983962\n",
      "[374]\ttraining's auc: 0.983967\n",
      "[375]\ttraining's auc: 0.983978\n",
      "[376]\ttraining's auc: 0.983983\n",
      "[377]\ttraining's auc: 0.983986\n",
      "[378]\ttraining's auc: 0.983993\n",
      "[379]\ttraining's auc: 0.984002\n",
      "[380]\ttraining's auc: 0.984007\n",
      "[381]\ttraining's auc: 0.984016\n",
      "[382]\ttraining's auc: 0.984023\n",
      "[383]\ttraining's auc: 0.984032\n",
      "[384]\ttraining's auc: 0.984039\n",
      "[385]\ttraining's auc: 0.98405\n",
      "[386]\ttraining's auc: 0.984053\n",
      "[387]\ttraining's auc: 0.984063\n",
      "[388]\ttraining's auc: 0.984071\n",
      "[389]\ttraining's auc: 0.984081\n",
      "[390]\ttraining's auc: 0.984087\n",
      "[391]\ttraining's auc: 0.984089\n",
      "[392]\ttraining's auc: 0.984095\n",
      "[393]\ttraining's auc: 0.984099\n",
      "[394]\ttraining's auc: 0.984103\n",
      "[395]\ttraining's auc: 0.984111\n",
      "[396]\ttraining's auc: 0.984131\n",
      "[397]\ttraining's auc: 0.984134\n",
      "[398]\ttraining's auc: 0.984145\n",
      "[399]\ttraining's auc: 0.984149\n",
      "[400]\ttraining's auc: 0.984158\n",
      "[401]\ttraining's auc: 0.984161\n",
      "[402]\ttraining's auc: 0.984167\n",
      "[403]\ttraining's auc: 0.984174\n",
      "[404]\ttraining's auc: 0.984185\n",
      "[405]\ttraining's auc: 0.984188\n",
      "[406]\ttraining's auc: 0.984192\n",
      "[407]\ttraining's auc: 0.984194\n",
      "[408]\ttraining's auc: 0.984197\n",
      "[409]\ttraining's auc: 0.984206\n",
      "[410]\ttraining's auc: 0.984215\n",
      "[411]\ttraining's auc: 0.984222\n",
      "[412]\ttraining's auc: 0.98423\n",
      "[413]\ttraining's auc: 0.984243\n",
      "[414]\ttraining's auc: 0.984245\n",
      "[415]\ttraining's auc: 0.984254\n",
      "[416]\ttraining's auc: 0.984258\n",
      "[417]\ttraining's auc: 0.98427\n",
      "[418]\ttraining's auc: 0.984277\n",
      "[419]\ttraining's auc: 0.984284\n",
      "[420]\ttraining's auc: 0.984288\n",
      "[421]\ttraining's auc: 0.984297\n",
      "[422]\ttraining's auc: 0.984301\n",
      "[423]\ttraining's auc: 0.984304\n",
      "[424]\ttraining's auc: 0.984311\n",
      "[425]\ttraining's auc: 0.984318\n",
      "[426]\ttraining's auc: 0.984324\n",
      "[427]\ttraining's auc: 0.984334\n",
      "[428]\ttraining's auc: 0.984338\n",
      "[429]\ttraining's auc: 0.984344\n",
      "[430]\ttraining's auc: 0.984351\n",
      "[431]\ttraining's auc: 0.984358\n",
      "[432]\ttraining's auc: 0.984363\n",
      "[433]\ttraining's auc: 0.984369\n",
      "[434]\ttraining's auc: 0.984375\n",
      "[435]\ttraining's auc: 0.984378\n",
      "[436]\ttraining's auc: 0.984385\n",
      "[437]\ttraining's auc: 0.984387\n",
      "[438]\ttraining's auc: 0.984395\n",
      "[439]\ttraining's auc: 0.984399\n",
      "[440]\ttraining's auc: 0.984405\n",
      "[441]\ttraining's auc: 0.984407\n",
      "[442]\ttraining's auc: 0.984411\n",
      "[443]\ttraining's auc: 0.984414\n",
      "[444]\ttraining's auc: 0.984419\n",
      "[445]\ttraining's auc: 0.984425\n",
      "[446]\ttraining's auc: 0.984429\n",
      "[447]\ttraining's auc: 0.98443\n",
      "[448]\ttraining's auc: 0.984432\n",
      "[449]\ttraining's auc: 0.984437\n",
      "[450]\ttraining's auc: 0.984446\n",
      "[451]\ttraining's auc: 0.98445\n",
      "[452]\ttraining's auc: 0.984453\n",
      "[453]\ttraining's auc: 0.984457\n",
      "[454]\ttraining's auc: 0.984461\n",
      "[455]\ttraining's auc: 0.984463\n",
      "[456]\ttraining's auc: 0.984469\n",
      "[457]\ttraining's auc: 0.984478\n",
      "[458]\ttraining's auc: 0.984483\n",
      "[459]\ttraining's auc: 0.984489\n",
      "[460]\ttraining's auc: 0.984496\n",
      "[461]\ttraining's auc: 0.984503\n",
      "[462]\ttraining's auc: 0.984508\n",
      "[463]\ttraining's auc: 0.984511\n",
      "[464]\ttraining's auc: 0.984515\n",
      "[465]\ttraining's auc: 0.98452\n",
      "[466]\ttraining's auc: 0.984523\n",
      "[467]\ttraining's auc: 0.984526\n",
      "[468]\ttraining's auc: 0.98453\n",
      "[469]\ttraining's auc: 0.984533\n",
      "[470]\ttraining's auc: 0.984541\n",
      "[471]\ttraining's auc: 0.984544\n",
      "[472]\ttraining's auc: 0.984547\n",
      "[473]\ttraining's auc: 0.984551\n",
      "[474]\ttraining's auc: 0.98456\n",
      "[475]\ttraining's auc: 0.984567\n",
      "[476]\ttraining's auc: 0.984571\n",
      "[477]\ttraining's auc: 0.984576\n",
      "[478]\ttraining's auc: 0.984578\n",
      "[479]\ttraining's auc: 0.984584\n",
      "[480]\ttraining's auc: 0.984594\n",
      "[481]\ttraining's auc: 0.984596\n",
      "[482]\ttraining's auc: 0.984602\n",
      "[483]\ttraining's auc: 0.984603\n",
      "[484]\ttraining's auc: 0.984605\n",
      "[485]\ttraining's auc: 0.984611\n",
      "[486]\ttraining's auc: 0.984613\n",
      "[487]\ttraining's auc: 0.984619\n",
      "[488]\ttraining's auc: 0.984625\n",
      "[489]\ttraining's auc: 0.984628\n",
      "[490]\ttraining's auc: 0.98463\n",
      "[491]\ttraining's auc: 0.984636\n",
      "[492]\ttraining's auc: 0.984641\n",
      "[493]\ttraining's auc: 0.984646\n",
      "[494]\ttraining's auc: 0.984655\n",
      "[495]\ttraining's auc: 0.984661\n",
      "[496]\ttraining's auc: 0.984664\n",
      "[497]\ttraining's auc: 0.984668\n",
      "[498]\ttraining's auc: 0.984671\n",
      "[499]\ttraining's auc: 0.984675\n",
      "[500]\ttraining's auc: 0.984677\n",
      "[501]\ttraining's auc: 0.984684\n",
      "[502]\ttraining's auc: 0.98469\n",
      "[503]\ttraining's auc: 0.984694\n",
      "[504]\ttraining's auc: 0.9847\n",
      "[505]\ttraining's auc: 0.984708\n",
      "[506]\ttraining's auc: 0.984712\n",
      "[507]\ttraining's auc: 0.984716\n",
      "[508]\ttraining's auc: 0.984718\n",
      "[509]\ttraining's auc: 0.984722\n",
      "[510]\ttraining's auc: 0.984725\n",
      "[511]\ttraining's auc: 0.984727\n",
      "[512]\ttraining's auc: 0.984729\n",
      "[513]\ttraining's auc: 0.984731\n",
      "[514]\ttraining's auc: 0.984733\n",
      "[515]\ttraining's auc: 0.984739\n",
      "[516]\ttraining's auc: 0.984741\n",
      "[517]\ttraining's auc: 0.984747\n",
      "[518]\ttraining's auc: 0.98475\n",
      "[519]\ttraining's auc: 0.984752\n",
      "[520]\ttraining's auc: 0.984755\n",
      "[521]\ttraining's auc: 0.984759\n",
      "[522]\ttraining's auc: 0.984763\n",
      "[523]\ttraining's auc: 0.984768\n",
      "[524]\ttraining's auc: 0.984771\n",
      "[525]\ttraining's auc: 0.984779\n",
      "[526]\ttraining's auc: 0.984783\n",
      "[527]\ttraining's auc: 0.984786\n",
      "[528]\ttraining's auc: 0.984787\n",
      "[529]\ttraining's auc: 0.98479\n",
      "[530]\ttraining's auc: 0.984794\n",
      "[531]\ttraining's auc: 0.984799\n",
      "[532]\ttraining's auc: 0.9848\n",
      "[533]\ttraining's auc: 0.984806\n",
      "[534]\ttraining's auc: 0.984808\n",
      "[535]\ttraining's auc: 0.984812\n",
      "[536]\ttraining's auc: 0.984815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[537]\ttraining's auc: 0.984815\n",
      "[538]\ttraining's auc: 0.984816\n",
      "[539]\ttraining's auc: 0.98482\n",
      "[540]\ttraining's auc: 0.984823\n",
      "[541]\ttraining's auc: 0.984828\n",
      "[542]\ttraining's auc: 0.98483\n",
      "[543]\ttraining's auc: 0.984831\n",
      "[544]\ttraining's auc: 0.984832\n",
      "[545]\ttraining's auc: 0.984835\n",
      "[546]\ttraining's auc: 0.98484\n",
      "[547]\ttraining's auc: 0.984844\n",
      "[548]\ttraining's auc: 0.98485\n",
      "[549]\ttraining's auc: 0.984851\n",
      "[550]\ttraining's auc: 0.984853\n",
      "[551]\ttraining's auc: 0.984856\n",
      "[552]\ttraining's auc: 0.98486\n",
      "[553]\ttraining's auc: 0.984863\n",
      "[554]\ttraining's auc: 0.984869\n",
      "[555]\ttraining's auc: 0.984872\n",
      "[556]\ttraining's auc: 0.984876\n",
      "[557]\ttraining's auc: 0.984878\n",
      "[558]\ttraining's auc: 0.984882\n",
      "[559]\ttraining's auc: 0.984885\n",
      "[560]\ttraining's auc: 0.98489\n",
      "[561]\ttraining's auc: 0.984891\n",
      "[562]\ttraining's auc: 0.984892\n",
      "[563]\ttraining's auc: 0.984895\n",
      "[564]\ttraining's auc: 0.984902\n",
      "[565]\ttraining's auc: 0.984906\n",
      "[566]\ttraining's auc: 0.98491\n",
      "[567]\ttraining's auc: 0.98491\n",
      "[568]\ttraining's auc: 0.984911\n",
      "[569]\ttraining's auc: 0.984916\n",
      "[570]\ttraining's auc: 0.984917\n",
      "[571]\ttraining's auc: 0.98492\n",
      "[572]\ttraining's auc: 0.984923\n",
      "[573]\ttraining's auc: 0.984925\n",
      "[574]\ttraining's auc: 0.98493\n",
      "[575]\ttraining's auc: 0.984933\n",
      "[576]\ttraining's auc: 0.984935\n",
      "[577]\ttraining's auc: 0.984937\n",
      "[578]\ttraining's auc: 0.984939\n",
      "[579]\ttraining's auc: 0.984941\n",
      "[580]\ttraining's auc: 0.984944\n",
      "[581]\ttraining's auc: 0.984949\n",
      "[582]\ttraining's auc: 0.984952\n",
      "[583]\ttraining's auc: 0.984958\n",
      "[584]\ttraining's auc: 0.984961\n",
      "[585]\ttraining's auc: 0.984964\n",
      "[586]\ttraining's auc: 0.98497\n",
      "[587]\ttraining's auc: 0.984976\n",
      "[588]\ttraining's auc: 0.98498\n",
      "[589]\ttraining's auc: 0.984985\n",
      "[590]\ttraining's auc: 0.984988\n",
      "[591]\ttraining's auc: 0.984989\n",
      "[592]\ttraining's auc: 0.984993\n",
      "[593]\ttraining's auc: 0.984995\n",
      "[594]\ttraining's auc: 0.984999\n",
      "[595]\ttraining's auc: 0.985003\n",
      "[596]\ttraining's auc: 0.985008\n",
      "[597]\ttraining's auc: 0.985012\n",
      "[598]\ttraining's auc: 0.985017\n",
      "[599]\ttraining's auc: 0.985019\n",
      "[600]\ttraining's auc: 0.985021\n",
      "[601]\ttraining's auc: 0.985027\n",
      "[602]\ttraining's auc: 0.985031\n"
     ]
    }
   ],
   "source": [
    "model_lgb, pred_lgb = lgb_predict(dtrain, online_test_x2, iterations_lgb2, params_lgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgb = sorted(zip(online_train_x2.columns, model_lgb.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True)\n",
    "importance_lgb = pd.DataFrame({'feature': importance_lgb})\n",
    "importance_lgb = importance_lgb.apply(lambda x: pd.Series(x['feature']), axis=1)\n",
    "importance_lgb.columns = ['feature', 'importance']\n",
    "importance_lgb.to_csv('importance-lgb-whole_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lgb = store_result(pd.read_csv('./test.csv', header=0, sep=',', usecols=['click_id']).click_id.astype(int), pred_lgb, 'prediction_chinese.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.save_model(\"model_chinese.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
